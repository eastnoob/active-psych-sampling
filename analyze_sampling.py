#!/usr/bin/env python3
"""åˆ†ææœ€æ–°é‡‡æ ·æ•°æ®ä¸­çš„é‡å¤ç‚¹"""

import pandas as pd
import numpy as np


def analyze_sampling_data(csv_path):
    # è¯»å–æ•°æ®
    df = pd.read_csv(csv_path)

    print("=== é‡‡æ ·æ•°æ®åˆ†æ ===")
    print(f"æ€»é‡‡æ ·ç‚¹æ•°: {len(df)}")
    print(f'Golden warmupé˜¶æ®µ: {len(df[df["phase"] == "golden_warmup"])} ä¸ªç‚¹')
    print(f'EUR optimizationé˜¶æ®µ: {len(df[df["phase"] == "eur_optimization"])} ä¸ªç‚¹')

    # æå–åæ ‡åˆ—
    coords_cols = ["x0", "x1", "x2", "x3", "x4", "x5"]
    coords = df[coords_cols]

    print("\n=== é‡å¤ç‚¹æ£€æŸ¥ ===")

    # æ£€æŸ¥å®Œå…¨é‡å¤çš„ç‚¹
    duplicates = coords.duplicated(keep=False)
    if duplicates.any():
        print("âŒ å‘ç°é‡å¤ç‚¹:")
        dup_points = df[duplicates]
        for idx, row in dup_points.iterrows():
            print(
                f'  è¿­ä»£{row["iteration"]} ({row["phase"]}): [{row["x0"]}, {row["x1"]}, {row["x2"]}, {row["x3"]}, {row["x4"]}, {row["x5"]}]'
            )
    else:
        print("âœ… æ²¡æœ‰å‘ç°å®Œå…¨é‡å¤çš„ç‚¹")

    # åˆ†é˜¶æ®µæ£€æŸ¥
    print("\n=== åˆ†é˜¶æ®µåˆ†æ ===")
    warmup = df[df["phase"] == "golden_warmup"]
    eur = df[df["phase"] == "eur_optimization"]

    print("Golden warmupç‚¹:")
    for idx, row in warmup.iterrows():
        print(
            f'  è¿­ä»£{row["iteration"]}: [{row["x0"]}, {row["x1"]}, {row["x2"]}, {row["x3"]}, {row["x4"]}, {row["x5"]}]'
        )

    print("\nEURé˜¶æ®µæ˜¯å¦é‡ç”¨äº†warmupç‚¹:")
    warmup_coords = warmup[coords_cols]
    eur_coords = eur[coords_cols]

    reuse_found = False
    for w_idx, w_row in warmup_coords.iterrows():
        w_point = w_row.values
        for e_idx, e_row in eur_coords.iterrows():
            e_point = e_row.values
            if np.allclose(w_point, e_point, atol=1e-6):
                w_iter = df.loc[w_idx, "iteration"]
                e_iter = df.loc[e_idx, "iteration"]
                print(f"  âŒ Warmupç‚¹{w_iter}è¢«EURè¿­ä»£{e_iter}é‡å¤ä½¿ç”¨: {w_point}")
                reuse_found = True

    if not reuse_found:
        print("  âœ… EURé˜¶æ®µæ²¡æœ‰é‡å¤ä½¿ç”¨warmupç‚¹")

    print("\n=== è·ç¦»åˆ†æ ===")
    min_distances = df["min_distance"].dropna()
    if len(min_distances) > 0:
        print(f"æœ€å°è·ç¦»ç»Ÿè®¡:")
        print(f"  å¹³å‡: {min_distances.mean():.3f}")
        print(f"  æœ€å°: {min_distances.min():.3f}")
        print(f"  æœ€å¤§: {min_distances.max():.3f}")
        zero_dist_count = (min_distances == 0.0).sum()
        if zero_dist_count > 0:
            print(f"  âš ï¸  é›¶è·ç¦»ç‚¹æ•°: {zero_dist_count} (å¯èƒ½æ˜¯é‡å¤ç‚¹)")
            # æ˜¾ç¤ºé›¶è·ç¦»ç‚¹çš„è¯¦æƒ…
            zero_dist_rows = df[df["min_distance"] == 0.0]
            for _, row in zero_dist_rows.iterrows():
                print(
                    f'    è¿­ä»£{row["iteration"]}: [{row["x0"]}, {row["x1"]}, {row["x2"]}, {row["x3"]}, {row["x4"]}, {row["x5"]}]'
                )
        else:
            print(f"  âœ… æ²¡æœ‰é›¶è·ç¦»ç‚¹")

    return not duplicates.any() and not reuse_found


if __name__ == "__main__":
    csv_path = "tests/is_EUR_work/00_plans/251206/scripts/results/20251209_172709/data_files/test_data.csv"
    success = analyze_sampling_data(csv_path)

    if success:
        print("\nğŸ‰ å†å²ç‚¹æ’é™¤åŠŸèƒ½å·¥ä½œæ­£å¸¸ï¼Œæ²¡æœ‰å‘ç°é‡å¤é‡‡æ ·ï¼")
    else:
        print("\nâš ï¸  å‘ç°äº†é‡å¤é‡‡æ ·é—®é¢˜ã€‚")
