# ==============================================================================
# Configuration: Pure Continuous Parameters with Learned Offset Mean
# ==============================================================================
#
# Use Case: Continuous parameter space with suspected global offset from BaseGP
# Mean Type: learned_offset (BaseGP mean + learnable offset, 1 extra parameter)
# Factory: CustomBaseGPResidualFactory (continuous only)
#
# Expected Performance: Use when subjects show systematic global shifts
# Trade-off: 1 extra parameter may hurt performance in small sample regimes
# ==============================================================================

[common]
lb = [0, 0, 0, 0, 0, 0]
ub = [1, 4, 4, 3, 2, 1]
parnames = [x0_dur, x1_freq, x2_intensity, x3_location, x4_texture, x5_pattern]
outcome_types = [single_probit]
strategy_names = [init_strat, opt_strat]
stimuli_per_trial = 1
n_params = 6

# Simulation target (optional, for testing)
target = 0.75

[init_strat]
# Initialization strategy: Sobol sampling
min_asks = 10
generator = SobolGenerator

[SobolGenerator]
stimuli_per_trial = 1
seed = 12345

[opt_strat]
# Optimization strategy: ModelWrapperStrategy with CustomBaseGPResidualFactory
min_asks = 20
generator = OptimizeAcqfGenerator
model = GPRegressionModel

[GPRegressionModel]
# Use custom residual learning factory
mean_covar_factory = CustomBaseGPResidualFactory
inducing_size = 10
inducing_point_method = auto

# Likelihood configuration
likelihood = ConfigurableGaussianLikelihood

[ConfigurableGaussianLikelihood]
# Fixed noise for probit responses
noise_prior = fixed
noise_value = 0.01

[CustomBaseGPResidualFactory]
# BaseGP mean configuration
basegp_scan_csv = extensions/example_data/design_space_scan.csv
mean_type = learned_offset
offset_prior_std = 0.10

# Lengthscale prior (修正后的loc，让prior mode ≈ BaseGP lengthscales)
lengthscale_prior = lognormal
ls_loc = [0.0166, -0.2634, 0.7133, -1.4744, 0.7983, 0.6391]
ls_scale = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]

# Output scale prior
fixed_kernel_amplitude = False
outputscale_prior = gamma

[OptimizeAcqfGenerator]
# Acquisition function: Expected Improvement
acqf = qLogNoisyExpectedImprovement
stimuli_per_trial = 1
restarts = 10
samps = 1000

# ==============================================================================
# Notes:
# - learned_offset adds 1 learnable parameter (offset ~ N(0, 0.10²))
# - Use this when you expect systematic global shifts from BaseGP
# - offset_prior_std controls the strength of the prior:
#   * 0.05: Strong prior (small expected shifts)
#   * 0.10: Medium prior (default, recommended)
#   * 0.20: Weak prior (large expected shifts)
# - For small samples (<30), pure_residual may perform better
# ==============================================================================
