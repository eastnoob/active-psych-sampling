# ==============================================================================
# Configuration: Mixed Parameters with Learned Offset Mean
# ==============================================================================
#
# Use Case: Mixed parameter space with suspected global offset from BaseGP
# Mean Type: learned_offset (BaseGP mean + learnable offset, 1 extra parameter)
# Factory: CustomBaseGPResidualMixedFactory
#
# Kernel: ProductKernel(MaternKernel × CategoricalKernel)
# Expected Performance: Use when subjects show systematic global shifts in mixed spaces
# ==============================================================================

[common]
lb = [0, 0, 0, 0]
ub = [1, 1, 2, 1]
parnames = [dur_continuous, freq_continuous, intensity_discrete, color_discrete]
outcome_types = [single_probit]
strategy_names = [init_strat, opt_strat]
stimuli_per_trial = 1
n_params = 4

# Simulation target (optional, for testing)
target = 0.75

[init_strat]
# Initialization strategy: Sobol sampling
min_asks = 10
generator = SobolGenerator

[SobolGenerator]
stimuli_per_trial = 1
seed = 12345

[opt_strat]
# Optimization strategy: ModelWrapperStrategy with CustomBaseGPResidualMixedFactory
min_asks = 20
generator = OptimizeAcqfGenerator
model = GPRegressionModel

[GPRegressionModel]
# Use custom mixed residual learning factory
mean_covar_factory = CustomBaseGPResidualMixedFactory
inducing_size = 10
inducing_point_method = auto

# Likelihood configuration
likelihood = ConfigurableGaussianLikelihood

[ConfigurableGaussianLikelihood]
# Fixed noise for probit responses
noise_prior = fixed
noise_value = 0.01

[CustomBaseGPResidualMixedFactory]
# Parameter type specification
continuous_params = [dur_continuous, freq_continuous]
discrete_params = {intensity_discrete: 3, color_discrete: 2}

# BaseGP mean configuration
basegp_scan_csv = extensions/example_data/design_space_scan_mixed.csv
mean_type = learned_offset
offset_prior_std = 0.10

# Lengthscale prior (ONLY for continuous params)
lengthscale_prior = lognormal
ls_loc = [0.0, -0.3]  # 2 values for 2 continuous params
ls_scale = [0.5, 0.5]

# Output scale prior
fixed_kernel_amplitude = False
outputscale_prior = gamma

[OptimizeAcqfGenerator]
# Acquisition function: Expected Improvement
acqf = qLogNoisyExpectedImprovement
stimuli_per_trial = 1
restarts = 10
samps = 1000

# ==============================================================================
# Notes:
# - learned_offset adds 1 learnable parameter (offset ~ N(0, 0.10²))
# - continuous_params: list of continuous parameter names
# - discrete_params: dict mapping discrete param names to number of categories
# - Dimension mapping in train_X: [continuous params | discrete params]
#   * dur_continuous: dim 0
#   * freq_continuous: dim 1
#   * intensity_discrete: dim 2 (values: 0, 1, 2)
#   * color_discrete: dim 3 (values: 0, 1)
# - ls_loc/ls_scale ONLY specify priors for continuous params
# - CategoricalKernel lengthscales for discrete params use default priors
# - Kernel structure: ScaleKernel(ProductKernel(MaternKernel, CategoricalKernel))
# - offset_prior_std controls the strength of the global offset prior
# ==============================================================================
