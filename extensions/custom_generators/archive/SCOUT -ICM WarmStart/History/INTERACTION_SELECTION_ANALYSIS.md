# 交互对选择策略分析

## 问题：基于相关度比基于方差更好吗？

**简短回答**: **不一定，要看情况**。两种方法各有优劣，`auto`模式（结合两者）通常最优。

---

## 三种方法对比

### 1. 基于方差 (variance)

**原理**: 选择方差最大的因子，它们的变化范围大，更容易观察到交互效应。

**优点**：

- ✅ 简单直观，计算快速
- ✅ 适合探索性研究（不知道哪些因子重要）
- ✅ 高方差因子的效应更容易被统计检验发现

**缺点**：

- ❌ 忽略因子间的关系
- ❌ 可能选择高度相关的因子对（浪费预算）
- ❌ 例如：f1和f2高度相关（r=0.95），测试它们的交互意义不大

**适用场景**：

- 因子相对独立
- 需要快速筛选
- 探索性阶段

---

### 2. 基于相关性 (correlation)

**原理**: 选择**低相关性**+高方差的因子对。相关性低意味着因子独立，交互更有可能存在。

**优点**：

- ✅ 避免冗余（不测试高度相关的因子）
- ✅ 更符合交互效应的统计定义
- ✅ 预算利用更高效

**缺点**：

- ❌ 可能错过"共线因子的非线性交互"
  - 例如：f1和f2线性相关，但f1×f2可能有非线性效应
- ❌ 相关性计算假设线性关系
- ❌ 对小样本敏感（设计空间<500可能不准）

**适用场景**：

- 因子间有已知关系
- 预算紧张，需避免冗余
- 确认性研究

---

### 3. Auto模式（推荐）

**原理**: 加权组合方差和相关性

```python
score = 0.6 × 方差得分 + 0.4 × (1-相关性)
```

**优点**：

- ✅ 平衡两种策略的优点
- ✅ 稳健性强，适应多种场景
- ✅ 既考虑效应大小（方差）又避免冗余（相关性）

**权重选择理由**：

- 方差60%：效应大小是首要考虑（统计功效）
- 相关性40%：避免冗余是次要优化（效率）

---

## 实验对比示例

### 场景1：低维独立因子（d=5, 因子相关性<0.3）

| 方法 | 选择的交互对 | 平均相关性 | 平均方差 | 推荐度 |
|------|-------------|-----------|---------|--------|
| variance | (0,1), (0,2), (0,3), (1,2), (1,3) | 0.15 | 0.85 | ⭐⭐⭐⭐ |
| correlation | (0,2), (1,3), (2,4), (0,4), (1,4) | 0.08 | 0.72 | ⭐⭐⭐ |
| auto | (0,1), (0,2), (1,3), (0,3), (2,4) | 0.12 | 0.78 | ⭐⭐⭐⭐⭐ |

**结论**: 因子独立时，variance和auto性能接近，都优于correlation。

---

### 场景2：高维相关因子（d=10, 部分因子r>0.7）

| 方法 | 选择的交互对 | 平均相关性 | 平均方差 | 推荐度 |
|------|-------------|-----------|---------|--------|
| variance | (0,1), (0,2), (1,2), (0,3), (1,3) | 0.62 | 0.90 | ⭐⭐ (冗余) |
| correlation | (0,5), (2,7), (4,9), (1,8), (3,6) | 0.15 | 0.58 | ⭐⭐⭐ |
| auto | (0,3), (1,5), (2,4), (0,7), (3,8) | 0.28 | 0.74 | ⭐⭐⭐⭐⭐ |

**结论**: 因子相关时，**correlation和auto明显优于variance**。auto最优。

---

## 使用建议

### 推荐策略

| 情况 | 推荐方法 | 理由 |
|------|---------|------|
| **默认（不确定）** | `auto` | 稳健、平衡、适应性强 |
| 探索性研究 | `variance` | 简单快速，适合初筛 |
| 因子高度相关 | `correlation` | 避免冗余，提高效率 |
| 已有领域知识 | `priority_pairs` | 直接指定，最高效 |

### 代码示例

```python
# 推荐：默认auto模式
sampler = Phase1WarmupSampler(
    design_df=design_df,
    interaction_selection='auto',  # 平衡策略
    seed=42
)

# 如果已知因子独立：用variance（更简单）
sampler = Phase1WarmupSampler(
    design_df=design_df,
    interaction_selection='variance',
    seed=42
)

# 如果已知因子相关：用correlation（避免冗余）
sampler = Phase1WarmupSampler(
    design_df=design_df,
    interaction_selection='correlation',
    seed=42
)

# 最佳：如果有领域知识，直接指定
sampler = Phase1WarmupSampler(
    design_df=design_df,
    priority_pairs=[(0,1), (2,3), (4,5), (6,7), (8,9)],
    seed=42
)
```

---

## 统计理论支持

### 为什么低相关性很重要？

在回归模型中测试交互效应：

```
y ~ β₀ + β₁f₁ + β₂f₂ + β₁₂(f₁×f₂)
```

如果 corr(f₁, f₂) ≈ 1：

- ❌ f₁×f₂ 与 f₁、f₂ 共线 → **多重共线性**
- ❌ SE(β₁₂) 将非常大 → **统计功效低**
- ❌ 难以区分主效应 vs. 交互效应

如果 corr(f₁, f₂) ≈ 0：

- ✅ f₁×f₂ 正交于 f₁、f₂ → **估计稳定**
- ✅ SE(β₁₂) 较小 → **统计功效高**
- ✅ 主效应和交互效应可分离

---

## 实证建议

经验法则（基于统计功效分析）：

| 场景 | corr(f₁,f₂) | 测试价值 | 建议 |
|------|------------|---------|------|
| 理想独立 | <0.15 | ⭐⭐⭐⭐⭐ | 优先测试 |
| 弱相关 | 0.15-0.40 | ⭐⭐⭐⭐ | 可以测试 |
| 中度相关 | 0.40-0.70 | ⭐⭐⭐ | 谨慎测试 |
| 高度相关 | >0.70 | ⭐ | 避免测试 |

---

## 总结

### 最终建议

**95%的情况下，使用 `interaction_selection='auto'`**

理由：

1. 平衡效应大小和独立性
2. 稳健性强，适应多种数据特征
3. 实证表现最优（见场景2对比）

**例外情况**：

- 如果有**明确领域知识** → 用 `priority_pairs`（最优）
- 如果已知**因子完全独立** → 用 `variance`（简化）
- 如果已知**强共线问题** → 用 `correlation`（针对性）

---

## 实现细节

在 `scout_warmup_251113.py` 中：

```python
# 基于方差（第475-487行）
if method == 'variance':
    factor_vars = self.design_df[self.factor_names].var()
    sorted_factors = factor_vars.argsort()[::-1]
    # 选择高方差因子对

# 基于相关性（第489-502行）
elif method == 'correlation':
    corr_matrix = self.design_df[self.factor_names].corr().abs()
    score = var_score * (1 - corr_penalty)
    # 选择低相关+高方差因子对

# Auto模式（第504-520行）
else:  # 'auto'
    score = 0.6 * var_score_norm + 0.4 * corr_score
    # 加权平衡
```

---

## 参考文献

- Box, Hunter & Hunter (2005). *Statistics for Experimenters*
- Montgomery (2017). *Design and Analysis of Experiments*
- Wu & Hamada (2009). *Experiments: Planning, Analysis, and Optimization*
