"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬ - ä¸¤é˜¶æ®µå®éªŒè§„åˆ’
åªéœ€ä¿®æ”¹ä¸‹æ–¹é…ç½®å‚æ•°ï¼Œå³å¯å¿«é€Ÿä½¿ç”¨é¢„çƒ­é‡‡æ ·å’Œæ•°æ®åˆ†æåŠŸèƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä¿®æ”¹ä¸‹æ–¹çš„é…ç½®å‚æ•°ï¼ˆSTEP 1æˆ–STEP 2ï¼‰
2. é€‰æ‹©è¦è¿è¡Œçš„æ­¥éª¤ï¼ˆMODEï¼‰
3. è¿è¡Œ: python quick_start.py

ğŸ”§ æœ¬è„šæœ¬ç°å·²æ”¯æŒæ–°çš„ API æ¥å£ï¼ˆå‘åå…¼å®¹ï¼‰
   - å†…éƒ¨ä½¿ç”¨ config_models.Step1Config, Step2Config, Step3Config
   - ä¿æŒåŸæœ‰çš„é…ç½®å­—å…¸æ ¼å¼ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰ä»£ç 
   - å¯é€‰ä½¿ç”¨æ–°çš„æµç¨‹ç®¡ç†å™¨è¿›è¡Œé“¾å¼è°ƒç”¨
"""

import sys
from pathlib import Path
import time
from typing import Dict, Any, Optional

# æ·»åŠ coreç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "core"))

# æ–°å¢ï¼šå¯¼å…¥é…ç½®æ¨¡å‹å’Œ API
try:
    from core.config_models import Step1Config, Step2Config, Step3Config
    from core.warmup_api import (
        run_step1 as api_run_step1,
        run_step2 as api_run_step2,
        run_step3 as api_run_step3,
        Step1Step2Chain,
        Step1Step2Step3Chain,
    )

    API_AVAILABLE = True
except ImportError:
    API_AVAILABLE = False
    print("[è­¦å‘Š] æ–°çš„ API æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿå®ç°")

# ============================================================================
# é…ç½®å‚æ•° - è¯·æ ¹æ®éœ€è¦ä¿®æ”¹
# ============================================================================

# é€‰æ‹©è¿è¡Œæ¨¡å¼
# "step1"      - ç”Ÿæˆé¢„çƒ­é‡‡æ ·æ–¹æ¡ˆ
# "step1.5"    - æ¨¡æ‹Ÿè¢«è¯•ä½œç­”ï¼ˆå¯é€‰ï¼Œç”¨äºæµ‹è¯•ï¼‰
# "step2"      - åˆ†æPhase 1æ•°æ®å¹¶ç”ŸæˆPhase 2å‚æ•°
# "step3"      - è®­ç»ƒ Base GP å¹¶æ‰«æè®¾è®¡ç©ºé—´
# "step2+3"    - æ•´åˆåˆ†æï¼šStep 2 + Step 3ï¼Œç”Ÿæˆç»Ÿä¸€æŠ¥å‘Šï¼ˆæ¨èï¼‰âœ¨
# "both"       - æ­¥éª¤1 -> æ‰‹åŠ¨å®éªŒ -> æ­¥éª¤2
# "all"        - æ­¥éª¤1 -> æ­¥éª¤1.5(æ¨¡æ‹Ÿ) -> æ­¥éª¤2 -> æ­¥éª¤3
# "chain12"    - ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2ï¼ˆæ¨èï¼‰
# "chain123"   - ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2->3ï¼ˆæ¨èï¼‰
MODE = "all"  # è¿è¡Œ Step1 -> Step1.5(æ¨¡æ‹Ÿ) -> Step2 -> Step3

# ----------------------------------------------------------------------------
# ALL æ¨¡å¼ä¸“ç”¨é…ç½®ï¼šç»Ÿä¸€æ§åˆ¶æ‰€æœ‰æ­¥éª¤çš„å‚æ•°ï¼ˆæ¨èä½¿ç”¨ï¼‰
# ----------------------------------------------------------------------------
# â­ åœ¨ ALL_CONFIG ä¸­è®¾ç½®çš„å‚æ•°ä¼šè¦†ç›–ä¸‹æ–¹å„ STEP é…ç½®ï¼Œå®ç°ç»Ÿä¸€ç®¡ç†
ALL_CONFIG = {
    # ==================== æµç¨‹æ§åˆ¶ ====================
    "base_output_dir": str(Path(__file__).parent / "phase1_analysis_output"),
    "run_step1_5": True,  # æ˜¯å¦è‡ªåŠ¨è¿è¡Œæ¨¡æ‹Ÿï¼ˆStep1.5ï¼‰
    "step1_5_use_result_dir_for_step2": True,  # Step2æ˜¯å¦ä½¿ç”¨Step1.5çš„ç»“æœ
    # ==================== è®¾è®¡ç©ºé—´ä¸é¢„ç®— ====================
    # è®¾è®¡ç©ºé—´CSVï¼ˆStep1å’ŒStep3å…±ç”¨ï¼‰
    "design_csv": str(
        Path(__file__).parent.parent.parent
        / "data"
        / "only_independences"
        / "data"
        / "only_independences"
        / "i9csy65bljq14ovww2v91-6532622b_JBmIu2QSKA.csv"
    ),
    # Phase 1 é¢„ç®—
    "n_subjects": 5,  # Phase 1 è¢«è¯•æ•°é‡
    "trials_per_subject": 30,  # Phase 1 æ¯ä¸ªè¢«è¯•çš„æµ‹è¯•æ¬¡æ•°
    "skip_interaction": False,  # æ˜¯å¦è·³è¿‡äº¤äº’æ•ˆåº”æ¢ç´¢
    "auto_confirm": True,  # æ˜¯å¦è‡ªåŠ¨ç¡®è®¤ï¼ˆTrue=ä¸è¯¢é—®ï¼‰
    # ==================== æ¨¡æ‹Ÿè¢«è¯•å‚æ•° (Step1.5) ====================
    "seed": 42,  # éšæœºç§å­
    "population_mean": 0.0,  # ç¾¤ä½“æƒé‡å‡å€¼
    "population_std": 0.25,  # ç¾¤ä½“æƒé‡æ ‡å‡†å·® (é™ä½åŸºç¡€æ–¹å·®ï¼)
    "individual_std_percent": 0.5,  # ä¸ªä½“å·®å¼‚æ¯”ä¾‹ (0.5Ã—0.25=0.125)
    "individual_corr": 0.0,  # ç‰¹å¾é—´ç›¸å…³
    # Likertè¾“å‡ºé…ç½®
    "likert_levels": 5,  # Likerté‡è¡¨ç­‰çº§æ•°
    "likert_mode": "tanh",  # tanh=æ‹ŸçœŸåˆ†å¸ƒ / percentile=å‡åŒ€åˆ†å¸ƒ
    "likert_sensitivity": 2.0,  # Likertçµæ•åº¦ (æ¨è: 1.5-2.5)
    # äº¤äº’æ•ˆåº”
    "interaction_pairs": [(3, 4), (0, 1)],  # æŒ‡å®šäº¤äº’å¯¹ (ç´¢å¼•ä»0å¼€å§‹)
    "num_interactions": 0,  # é¢å¤–éšæœºç”Ÿæˆçš„äº¤äº’é¡¹æ•°
    "interaction_scale": 0.25,  # äº¤äº’æƒé‡å°ºåº¦ (æ¨è: 0.2-0.3)
    # ==================== Phase 2 å‚æ•° (Step2) ====================
    "max_pairs": 5,  # æœ€å¤šé€‰æ‹©çš„äº¤äº’å¯¹æ•°é‡
    "min_pairs": 2,  # æœ€å°‘é€‰æ‹©çš„äº¤äº’å¯¹æ•°é‡
    "selection_method": "elbow",  # äº¤äº’å¯¹é€‰æ‹©æ–¹æ³•: elbow/bic_threshold/top_k
    "phase2_n_subjects": 20,  # Phase 2 è¢«è¯•æ•°é‡
    "phase2_trials_per_subject": 25,  # Phase 2 æ¯äººæµ‹è¯•æ¬¡æ•°
    "lambda_adjustment": 1.2,  # Î»è°ƒæ•´ç³»æ•° (1.0=ä¸è°ƒæ•´, >1.0=å¢å¼ºäº¤äº’æ¢ç´¢)
    # ==================== Base GP å‚æ•° (Step3) ====================
    "max_iters": 200,  # GPè®­ç»ƒè¿­ä»£æ•° (æµ‹è¯•ç”¨200, æ­£å¼ç”¨300+)
    "learning_rate": 0.05,  # å­¦ä¹ ç‡
    "use_cuda": False,  # æ˜¯å¦ä½¿ç”¨GPU
    "ensure_diversity": True,  # ç¡®ä¿é‡‡æ ·ç‚¹å¤šæ ·æ€§
}

# ==================== é«˜çº§ç”¨æˆ·é€‰é¡¹ ====================
# å¦‚æœéœ€è¦æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œå¯ä»¥åœ¨ ALL_CONFIG ä¸­åµŒå¥—å­å­—å…¸:
# ALL_CONFIG["step1"] = {"merge": True}  # è¦†ç›– Step1 ç‰¹å®šå‚æ•°
# ALL_CONFIG["step1_5"] = {"output_mode": "both"}  # è¦†ç›– Step1.5 ç‰¹å®šå‚æ•°
# ALL_CONFIG["step2"] = {"report_format": "txt"}  # è¦†ç›– Step2 ç‰¹å®šå‚æ•°
# ALL_CONFIG["step3"] = {"max_iters": 500}  # è¦†ç›– Step3 ç‰¹å®šå‚æ•°


# ----------------------------------------------------------------------------
# STEP 1 é…ç½®ï¼šç”Ÿæˆé¢„çƒ­é‡‡æ ·æ–¹æ¡ˆ
# ----------------------------------------------------------------------------
STEP1_CONFIG = {
    # è®¾è®¡ç©ºé—´CSVè·¯å¾„ï¼ˆåªåŒ…å«è‡ªå˜é‡åˆ—ï¼‰
    "design_csv_path": str(
        Path(__file__).parent.parent.parent
        / "data"
        / "only_independences"
        / "data"
        / "only_independences"
        / "i9csy65bljq14ovww2v91-6532622b_JBmIu2QSKA.csv"
    ),
    # é¢„ç®—å‚æ•°
    "n_subjects": 5,  # è¢«è¯•æ•°é‡
    "trials_per_subject": 30,  # æ¯ä¸ªè¢«è¯•çš„æµ‹è¯•æ¬¡æ•°
    "skip_interaction": False,  # æ˜¯å¦è·³è¿‡äº¤äº’æ•ˆåº”æ¢ç´¢ï¼ˆFalse=åŒ…å«äº¤äº’ï¼‰
    # è¾“å‡ºé…ç½®
    "output_dir": str(
        Path(__file__).parent / "sample" / time.strftime("%Y%m%d%H%M")
    ),  # è¾“å‡ºç›®å½•ï¼ˆæ ¼å¼ï¼šYYYYMMDDhhmmï¼‰
    "merge": False,  # æ˜¯å¦åˆå¹¶ä¸ºå•ä¸ªCSVï¼ˆFalse=æ¯ä¸ªè¢«è¯•ä¸€ä¸ªæ–‡ä»¶ï¼‰
    "subject_col_name": "subject_id",  # è¢«è¯•ç¼–å·åˆ—åï¼ˆä»…åœ¨merge=Trueæ—¶ä½¿ç”¨ï¼‰
    # æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œï¼ˆFalseä¼šè¯¢é—®ç¡®è®¤ï¼‰
    "auto_confirm": False,
}

# ----------------------------------------------------------------------------
# STEP 1.5 é…ç½®ï¼šæ¨¡æ‹Ÿè¢«è¯•ä½œç­”ï¼ˆå¯é€‰ï¼Œç”¨äºæµ‹è¯•æµç¨‹ï¼‰
# ----------------------------------------------------------------------------
STEP1_5_CONFIG = {
    # è¾“å…¥ï¼šStep 1ç”Ÿæˆçš„é‡‡æ ·æ–¹æ¡ˆç›®å½•
    "input_dir": str(
        Path(__file__).parent / "sample" / "202511302204"
    ),  # Step 1è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼‰ï¼Œåœ¨ MODE='all' æ—¶ä¼šè¢«è¦†ç›–ä¸º Step1 çš„è¾“å‡ºç›®å½•
    # æ¨¡æ‹Ÿå‚æ•°
    "seed": 42,  # éšæœºç§å­
    "output_mode": "combined",  # individual/combined/both
    "use_latent": False,  # æ˜¯å¦ä½¿ç”¨æ½œå˜é‡æ¨¡å‹
    "output_type": "likert",  # continuous/likert
    "likert_levels": 5,
    "likert_mode": "tanh",  # tanh=çœŸå®äººç±»åˆ†å¸ƒï¼ˆä¸­å¿ƒåå¤šï¼‰/ percentile=å¼ºåˆ¶å‡åŒ€
    "likert_sensitivity": 2.0,  # >1ä½¿åˆ†å¸ƒæ›´é›†ä¸­äºä¸­é—´å€¼ï¼ˆæ›´æ‹ŸçœŸï¼‰
    # è¢«è¯•å‚æ•° â­è°ƒæ•´ä¸ºæ›´æ‹ŸçœŸçš„å‚æ•°
    "population_mean": 0.0,
    "population_std": 0.4,  # ç¾¤ä½“æƒé‡åˆ†å¸ƒèŒƒå›´
    "individual_std_percent": 0.4,  # ä¸ªä½“å·®å¼‚=40% (0.4Ã—0.4=0.16, æ¨èå€¼ï¼Œé™ä½è¢«è¯•é—´å·®å¼‚)
    "individual_corr": 0.0,  # ç‰¹å¾é—´ç›¸å…³
    # äº¤äº’æ•ˆåº” â­å‡å°‘äº¤äº’å¯¹æ•°é‡
    "interaction_pairs": [(3, 4), (0, 1)],  # å‡å°‘åˆ°2ä¸ªäº¤äº’å¯¹ï¼ˆæ›´å¸¸è§ï¼‰
    "num_interactions": 0,  # é¢å¤–éšæœºç”Ÿæˆçš„äº¤äº’é¡¹æ•°
    "interaction_scale": 0.25,  # é™ä½äº¤äº’å¼ºåº¦ï¼ˆ0.4â†’0.25ï¼‰
    # è¾“å‡ºé…ç½®
    "clean": True,  # æ¸…ç†ä¹‹å‰çš„ç»“æœ
    # æ¨¡å‹æ˜¾ç¤ºä¸ä¿å­˜ â­æ–°å¢
    "print_model": True,  # æ˜¯å¦åœ¨æ§åˆ¶å°æ‰“å°æ¨¡å‹è§„æ ¼
    "save_model_summary": True,  # æ˜¯å¦ä¿å­˜æ¨¡å‹æ‘˜è¦åˆ°å•ç‹¬æ–‡ä»¶
    "model_summary_format": "txt",  # txt/md/both - æ¨¡å‹æ‘˜è¦æ ¼å¼
}

# ----------------------------------------------------------------------------
# STEP 2 é…ç½®ï¼šåˆ†æPhase 1æ•°æ®
# ----------------------------------------------------------------------------
STEP2_CONFIG = {
    # ========== å®éªŒæ•°æ®è·¯å¾„ï¼ˆäºŒé€‰ä¸€ï¼Œæ³¨é‡Šæ‰ä¸ç”¨çš„ï¼‰ ==========
    #
    # ã€æ–¹å¼1ã€‘ç›®å½•æ¨¡å¼ - è‡ªåŠ¨è¯»å–æ‰€æœ‰ subject_*.csvï¼ˆæ¨èï¼‰
    #   - ä¼˜ç‚¹: ç›´æ¥ä½¿ç”¨ Step 1.5 çš„ result ç›®å½•ï¼Œæ— éœ€æ‰‹åŠ¨åˆå¹¶
    #   - ç†è§£: æ¯ä¸ª subject_*.csv æ–‡ä»¶ä»£è¡¨ä¸€ä¸ªè¢«è¯•çš„æ•°æ®
    #   - subjectåˆ—ä¼šè‡ªåŠ¨ä»æ–‡ä»¶åç”Ÿæˆ (subject_1, subject_2, ...)
    "data_csv_path": str(Path(__file__).parent / "sample" / "202511302204" / "result"),
    # ã€æ–¹å¼2ã€‘æ–‡ä»¶æ¨¡å¼ - è¯»å–å•ä¸ªåˆå¹¶CSV
    #   - é€‚ç”¨: å·²ç»æ‰‹åŠ¨åˆå¹¶äº†æ‰€æœ‰è¢«è¯•æ•°æ®
    #   - è¦æ±‚: CSVä¸­å¿…é¡»åŒ…å« subject åˆ—å’Œå“åº”åˆ—
    # "data_csv_path": str(Path(__file__).parent / "sample" / "202511302204" / "result" / "combined_results.csv"),
    # åˆ—åé…ç½®
    "subject_col": "subject",  # è¢«è¯•ç¼–å·åˆ—å
    "response_col": "y",  # å“åº”å˜é‡åˆ—å
    # åˆ†æå‚æ•°
    "max_pairs": 5,  # æœ€å¤šé€‰æ‹©çš„äº¤äº’å¯¹æ•°é‡
    "min_pairs": 2,  # æœ€å°‘é€‰æ‹©çš„äº¤äº’å¯¹æ•°é‡
    "selection_method": "elbow",  # é€‰æ‹©æ–¹æ³•ï¼šelbow/bic_threshold/top_k
    # Phase 2å‚æ•°
    "phase2_n_subjects": 20,  # Phase 2è¢«è¯•æ•°
    "phase2_trials_per_subject": 25,  # Phase 2æ¯äººæµ‹è¯•æ¬¡æ•°
    "lambda_adjustment": 1.2,  # Î»è°ƒæ•´ç³»æ•°ï¼ˆ1.0=ä¸è°ƒæ•´ï¼Œ1.2=å¢å¼º20%äº¤äº’æ¢ç´¢ï¼‰
    # è¾“å‡ºé…ç½®
    "output_dir": str(Path(__file__).parent / "step2" / time.strftime("%Y%m%d%H%M")),
    "prefix": "phase1",
    "report_format": "md",  # æŠ¥å‘Šæ ¼å¼ï¼š'md'(é»˜è®¤) æˆ– 'txt'
}

# ----------------------------------------------------------------------------
# STEP 3 é…ç½®ï¼šBase GP (Matern2.5 + ARD) ä¸è®¾è®¡ç©ºé—´æ‰«æ
# ----------------------------------------------------------------------------
STEP3_CONFIG = {
    # ========== Phase1 æ•°æ®è·¯å¾„ï¼ˆäºŒé€‰ä¸€ï¼Œæ³¨é‡Šæ‰ä¸ç”¨çš„ï¼‰ ==========
    #
    # ã€æ–¹å¼1ã€‘ç›®å½•æ¨¡å¼ - è‡ªåŠ¨è¯»å–æ‰€æœ‰ subject_*.csvï¼ˆæ¨èï¼‰
    #   - ä¼˜ç‚¹: ç›´æ¥ä½¿ç”¨ Step 1.5 çš„ result ç›®å½•
    #   - ç†è§£: æ¯ä¸ª subject_*.csv æ–‡ä»¶ä»£è¡¨ä¸€ä¸ªè¢«è¯•çš„æ•°æ®
    #   - subjectåˆ—ä¼šè‡ªåŠ¨ä»æ–‡ä»¶åç”Ÿæˆ
    "data_csv_path": str(Path(__file__).parent / "sample" / "202511302204" / "result"),
    # ã€æ–¹å¼2ã€‘æ–‡ä»¶æ¨¡å¼ - è¯»å–å•ä¸ªåˆå¹¶CSV
    #   - é€‚ç”¨: å·²ç»æ‰‹åŠ¨åˆå¹¶äº†æ‰€æœ‰è¢«è¯•æ•°æ®
    #   - è¦æ±‚: CSVä¸­å¿…é¡»åŒ…å« subject åˆ—å’Œå“åº”åˆ—
    # "data_csv_path": str(Path(__file__).parent / "sample" / "202511302204" / "result" / "combined_results.csv"),
    # åˆ—åé…ç½®
    "subject_col": "subject",  # è¢«è¯•åˆ—
    "response_col": "y",  # å“åº”åˆ—
    # è®¾è®¡ç©ºé—´ CSV (åªå«è‡ªå˜é‡åˆ—ï¼Œä¸ Phase1 å› å­åŒå)
    "design_space_csv": str(
        Path(__file__).parent.parent.parent
        / "data"
        / "only_independences"
        / "data"
        / "only_independences"
        / "i9csy65bljq14ovww2v91-6532622b_JBmIu2QSKA.csv"
    ),
    # è®­ç»ƒå‚æ•°
    "max_iters": 200,  # æµ‹è¯•å¿«é€Ÿè¿­ä»£ï¼Œå¯æ ¹æ®éœ€è¦æé«˜åˆ°300
    "learning_rate": 0.05,
    "use_cuda": False,
    # é‡‡æ ·å¤šæ ·æ€§æ£€æŸ¥ï¼šè‹¥ä¸ºTrueï¼Œç¡®ä¿Sample 3ä¸Sample 1/2ä¸é‡å¤ï¼›è‹¥å†²çªï¼Œé€‰Stdç¬¬äºŒé«˜çš„ç‚¹
    "ensure_diversity": True,
    # è¾“å‡ºç›®å½•
    "output_dir": str(
        Path(__file__).parent
        / "phase1_analysis_output"
        / time.strftime("%Y%m%d%H%M")
        / "base_gp"
    ),
}


# ============================================================================
# é…ç½®è½¬æ¢è¾…åŠ©å‡½æ•°
# ============================================================================


def _dict_to_step1_config(config_dict: Dict[str, Any]) -> Step1Config:
    """å°†å­—å…¸é…ç½®è½¬æ¢ä¸º Step1Config å¯¹è±¡"""
    return Step1Config(
        design_csv_path=config_dict["design_csv_path"],
        n_subjects=config_dict["n_subjects"],
        trials_per_subject=config_dict["trials_per_subject"],
        skip_interaction=config_dict.get("skip_interaction", True),
        output_dir=config_dict.get("output_dir", None),
        merge=config_dict.get("merge", False),
        subject_col_name=config_dict.get("subject_col_name", "subject_id"),
        auto_confirm=config_dict.get("auto_confirm", True),
    )


def _dict_to_step2_config(config_dict: Dict[str, Any]) -> Step2Config:
    """å°†å­—å…¸é…ç½®è½¬æ¢ä¸º Step2Config å¯¹è±¡"""
    return Step2Config(
        data_csv_path=config_dict["data_csv_path"],
        subject_col=config_dict.get("subject_col", "subject"),
        response_col=config_dict.get("response_col", "y"),
        max_pairs=config_dict.get("max_pairs", 5),
        min_pairs=config_dict.get("min_pairs", 1),
        selection_method=config_dict.get("selection_method", "elbow"),
        phase2_n_subjects=config_dict.get("phase2_n_subjects", 20),
        phase2_trials_per_subject=config_dict.get("phase2_trials_per_subject", 25),
        lambda_adjustment=config_dict.get("lambda_adjustment", 1.0),
        output_dir=config_dict.get("output_dir", None),
        prefix=config_dict.get("prefix", "phase1"),
        report_format=config_dict.get("report_format", "md"),
    )


def _dict_to_step3_config(config_dict: Dict[str, Any]) -> Step3Config:
    """å°†å­—å…¸é…ç½®è½¬æ¢ä¸º Step3Config å¯¹è±¡"""
    return Step3Config(
        data_csv_path=config_dict["data_csv_path"],
        design_space_csv=config_dict["design_space_csv"],
        subject_col=config_dict.get("subject_col", "subject"),
        response_col=config_dict.get("response_col", "y"),
        max_iters=config_dict.get("max_iters", 300),
        learning_rate=config_dict.get("learning_rate", 0.01),
        use_cuda=config_dict.get("use_cuda", False),
        ensure_diversity=config_dict.get("ensure_diversity", True),
        output_dir=config_dict.get("output_dir", None),
    )


def _apply_all_config() -> None:
    """
    å°† ALL_CONFIG ä¸­çš„å…¨å±€è®¾ç½®åˆå¹¶åˆ°å„ STEP é…ç½®å­—å…¸ä¸­ã€‚

    æ”¯æŒä¸¤ç§è¦†ç›–æ¨¡å¼ï¼š
      1. åµŒå¥—å­—å…¸æ¨¡å¼ï¼šALL_CONFIG['step1'] = {...} ç›´æ¥è¦†ç›–å¯¹åº”é…ç½®
      2. é¡¶çº§å‚æ•°æ¨¡å¼ï¼šALL_CONFIG['n_subjects'] è‡ªåŠ¨åˆ†å‘åˆ°ç›¸å…³é…ç½®
    """
    # ========== 1. åµŒå¥—å­—å…¸æ¨¡å¼ï¼šç›´æ¥åˆå¹¶ ==========
    for key, target in (
        ("step1", STEP1_CONFIG),
        ("step1_5", STEP1_5_CONFIG),
        ("step2", STEP2_CONFIG),
        ("step3", STEP3_CONFIG),
    ):
        if isinstance(ALL_CONFIG.get(key), dict):
            target.update(ALL_CONFIG[key])

    # ========== 2. é¡¶çº§å‚æ•°æ¨¡å¼ï¼šæ™ºèƒ½åˆ†å‘ ==========

    # --- Step1 å‚æ•° ---
    for param in [
        "n_subjects",
        "trials_per_subject",
        "skip_interaction",
        "auto_confirm",
    ]:
        if param in ALL_CONFIG:
            STEP1_CONFIG[param] = ALL_CONFIG[param]

    # è®¾è®¡ç©ºé—´æ–‡ä»¶
    if "design_csv" in ALL_CONFIG:
        STEP1_CONFIG["design_csv_path"] = ALL_CONFIG["design_csv"]
        STEP3_CONFIG["design_space_csv"] = ALL_CONFIG["design_csv"]  # Step3ä¹Ÿç”¨åŒä¸€ä¸ª

    # --- Step1.5 å‚æ•° ---
    step1_5_params = [
        "seed",
        "population_mean",
        "population_std",
        "individual_std_percent",
        "individual_corr",
        "likert_levels",
        "likert_mode",
        "likert_sensitivity",
        "interaction_pairs",
        "num_interactions",
        "interaction_scale",
    ]
    for param in step1_5_params:
        if param in ALL_CONFIG:
            STEP1_5_CONFIG[param] = ALL_CONFIG[param]

    # --- Step2 å‚æ•° ---
    step2_params = [
        "max_pairs",
        "min_pairs",
        "selection_method",
        "phase2_n_subjects",
        "phase2_trials_per_subject",
        "lambda_adjustment",
    ]
    for param in step2_params:
        if param in ALL_CONFIG:
            STEP2_CONFIG[param] = ALL_CONFIG[param]

    # --- Step3 å‚æ•° ---
    step3_params = ["max_iters", "learning_rate", "use_cuda", "ensure_diversity"]
    for param in step3_params:
        if param in ALL_CONFIG:
            STEP3_CONFIG[param] = ALL_CONFIG[param]

    # --- ç‰¹æ®Šè¦†ç›–ï¼ˆå‘åå…¼å®¹æ—§ç‰ˆé…ç½®ï¼‰ ---
    if "step2_data_csv" in ALL_CONFIG:
        STEP2_CONFIG["data_csv_path"] = ALL_CONFIG["step2_data_csv"]

    if "step3_design_space_csv" in ALL_CONFIG:
        STEP3_CONFIG["design_space_csv"] = ALL_CONFIG["step3_design_space_csv"]


# ç«‹å³åº”ç”¨ ALL_CONFIG çš„è¦†ç›–ï¼ˆå¦‚æœç”¨æˆ·å¸Œæœ›æŠŠæ‰€æœ‰é…ç½®æ”¾åˆ° ALL_CONFIG ä¸­ï¼‰
_apply_all_config()


# ============================================================================
# ä¸»ç¨‹åº - æ— éœ€ä¿®æ”¹
# ============================================================================


def run_step1():
    """è¿è¡Œæ­¥éª¤1ï¼šç”Ÿæˆé¢„çƒ­é‡‡æ ·æ–¹æ¡ˆ"""
    print("=" * 80)
    print("æ­¥éª¤1ï¼šç”Ÿæˆé¢„çƒ­é‡‡æ ·æ–¹æ¡ˆ")
    print("=" * 80)
    print()

    # ä½¿ç”¨æ–°çš„ APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if API_AVAILABLE:
        try:
            config = _dict_to_step1_config(STEP1_CONFIG)
            result = api_run_step1(config)

            print("[OK] é‡‡æ ·æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼")
            print(f"  æ–‡ä»¶æ•°: {len(result.exported_files)}")
            print(f"  ä¿å­˜ä½ç½®: {result.output_dir}/")
            print(f"  é¢„ç®—è¯„ä¼°: {result.budget_adequacy}")
            print()
            print("=" * 80)
            print("ä¸‹ä¸€æ­¥ï¼š")
            print("  1. æŒ‰ç…§ç”Ÿæˆçš„CSVæ–‡ä»¶æ‰§è¡Œå®éªŒ")
            print("  2. æ”¶é›†å“åº”æ•°æ®ï¼ˆå› å˜é‡ï¼‰")
            print("  3. å°†å“åº”å€¼æ·»åŠ åˆ°CSVä¸­")
            print("  4. è¿è¡Œ python quick_start.pyï¼ˆè®¾ç½® MODE='step2'ï¼‰")
            print("=" * 80)
            print()
            return

        except Exception as e:
            print(f"[è­¦å‘Š] æ–° API è¿è¡Œå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿå®ç°: {e}")

    # ä¼ ç»Ÿå®ç°ï¼ˆå‘åå…¼å®¹ï¼‰
    from core.warmup_sampler import WarmupSampler

    # æ£€æŸ¥è®¾è®¡ç©ºé—´æ–‡ä»¶
    design_path = Path(STEP1_CONFIG["design_csv_path"])
    if not design_path.exists():
        print(f"[é”™è¯¯] è®¾è®¡ç©ºé—´æ–‡ä»¶ä¸å­˜åœ¨: {STEP1_CONFIG['design_csv_path']}")
        print()
        print("è¯·ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨ï¼Œä¸”åŒ…å«æ‰€æœ‰å› å­åˆ—ï¼ˆåªæœ‰è‡ªå˜é‡ï¼Œä¸åŒ…å«å› å˜é‡ï¼‰")
        print("ç¤ºä¾‹æ ¼å¼:")
        print("  density,height,greenery,street_width,landmark,style")
        print("  1,1,1,1,1,1")
        print("  1,1,1,1,1,2")
        print("  ...")
        sys.exit(1)

    # åˆå§‹åŒ–é‡‡æ ·å™¨
    try:
        sampler = WarmupSampler(STEP1_CONFIG["design_csv_path"])
    except Exception as e:
        print(f"[é”™è¯¯] åŠ è½½è®¾è®¡ç©ºé—´å¤±è´¥: {e}")
        sys.exit(1)

    # è¯„ä¼°é¢„ç®—
    print("å½“å‰é…ç½®:")
    print(f"  è¢«è¯•æ•°: {STEP1_CONFIG['n_subjects']}äºº")
    print(f"  æ¯äººtrials: {STEP1_CONFIG['trials_per_subject']}æ¬¡")
    print(
        f"  æ€»é¢„ç®—: {STEP1_CONFIG['n_subjects'] * STEP1_CONFIG['trials_per_subject']}æ¬¡"
    )
    print(f"  è·³è¿‡äº¤äº’: {'æ˜¯' if STEP1_CONFIG['skip_interaction'] else 'å¦'}")
    print()

    adequacy, budget = sampler.evaluate_budget(
        n_subjects=STEP1_CONFIG["n_subjects"],
        trials_per_subject=STEP1_CONFIG["trials_per_subject"],
        skip_interaction=STEP1_CONFIG["skip_interaction"],
    )

    # è¯¢é—®ç¡®è®¤ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if not STEP1_CONFIG["auto_confirm"]:
        if adequacy in ["é¢„ç®—ä¸è¶³", "ä¸¥é‡ä¸è¶³"]:
            print(f"[!] é¢„ç®—è¯„ä¼°ä¸ºã€{adequacy}ã€‘ï¼Œä¸å»ºè®®ç»§ç»­")
            confirm = input("æ˜¯å¦ä»è¦ç”Ÿæˆé‡‡æ ·æ–¹æ¡ˆï¼Ÿ(y/N): ").strip().lower()
            if confirm != "y":
                print("[å–æ¶ˆ] å·²é€€å‡º")
                sys.exit(0)
        else:
            confirm = input("æ˜¯å¦ç”Ÿæˆé‡‡æ ·æ–¹æ¡ˆï¼Ÿ(Y/n): ").strip().lower()
            if confirm == "n":
                print("[å–æ¶ˆ] å·²é€€å‡º")
                sys.exit(0)

    # ç”Ÿæˆé‡‡æ ·æ–‡ä»¶
    try:
        exported_files = sampler.generate_samples(
            budget=budget,
            output_dir=STEP1_CONFIG["output_dir"],
            merge=STEP1_CONFIG["merge"],
            subject_col_name=STEP1_CONFIG["subject_col_name"],
        )

        print("[OK] é‡‡æ ·æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼")
        print(f"  æ–‡ä»¶æ•°: {len(exported_files)}")
        print(f"  ä¿å­˜ä½ç½®: {STEP1_CONFIG['output_dir']}/")
        print()
        print("=" * 80)
        print("ä¸‹ä¸€æ­¥ï¼š")
        print("  1. æŒ‰ç…§ç”Ÿæˆçš„CSVæ–‡ä»¶æ‰§è¡Œå®éªŒ")
        print("  2. æ”¶é›†å“åº”æ•°æ®ï¼ˆå› å˜é‡ï¼‰")
        print("  3. å°†å“åº”å€¼æ·»åŠ åˆ°CSVä¸­")
        print("  4. è¿è¡Œ python quick_start.pyï¼ˆè®¾ç½® MODE='step2'ï¼‰")
        print("=" * 80)
        print()

    except Exception as e:
        print(f"[é”™è¯¯] ç”Ÿæˆé‡‡æ ·æ–‡ä»¶å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


def run_step2():
    """è¿è¡Œæ­¥éª¤2ï¼šåˆ†æPhase 1æ•°æ®"""
    print("=" * 80)
    print("æ­¥éª¤2ï¼šåˆ†æPhase 1æ•°æ®")
    print("=" * 80)
    print()

    # ä½¿ç”¨æ–°çš„ APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if API_AVAILABLE:
        try:
            config = _dict_to_step2_config(STEP2_CONFIG)
            result = api_run_step2(config)

            print("[OK] åˆ†æå®Œæˆï¼")
            print(f"  ç­›é€‰çš„äº¤äº’å¯¹: {len(result['analysis']['selected_pairs'])}ä¸ª")
            print(f"  æ€»é¢„ç®—: {result['phase2_config']['total_budget']}æ¬¡")
            print(
                f"  Î»: {result['phase2_config']['lambda_init']:.3f} -> {result['phase2_config']['lambda_end']:.3f}"
            )
            print(
                f"  Î³: {result['phase2_config']['gamma_init']:.3f} -> {result['phase2_config']['gamma_end']:.3f}"
            )
            print(
                f"  ä¸­æœŸè¯Šæ–­: ç¬¬{result['phase2_config']['mid_diagnostic_trial']}æ¬¡trial"
            )
            print()
            print("=" * 80)
            print("ä¸‹ä¸€æ­¥ï¼š")
            print("  1. æŸ¥çœ‹åˆ†ææŠ¥å‘Š:")
            print(f"     {result['files']['report']}")
            print("  2. é˜…è¯»Phase 2ä½¿ç”¨æŒ‡å—:")
            print(f"     {result['files']['usage_guide']}")
            print("  3. åœ¨EUR-ANOVAä¸­åŠ è½½é…ç½®:")
            print(f"     - JSON: {result['files']['json_config']}")
            print(f"     - NumPy: {result['files']['npz_schedules']}")
            print("=" * 80)
            print()
            return

        except Exception as e:
            print(f"[è­¦å‘Š] æ–° API è¿è¡Œå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿå®ç°: {e}")

    # ä¼ ç»Ÿå®ç°ï¼ˆå‘åå…¼å®¹ï¼‰
    from core.analyze_phase1 import Phase1DataAnalyzer

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_path = Path(STEP2_CONFIG["data_csv_path"])
    if not data_path.exists():
        print(f"[é”™è¯¯] æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {STEP2_CONFIG['data_csv_path']}")
        print()
        print("è¯·ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨ï¼Œä¸”åŒ…å«ä»¥ä¸‹åˆ—:")
        print(f"  - è¢«è¯•ç¼–å·åˆ—: {STEP2_CONFIG['subject_col']}")
        print(f"  - å“åº”å˜é‡åˆ—: {STEP2_CONFIG['response_col']}")
        print("  - æ‰€æœ‰å› å­åˆ—")
        print()
        print("ç¤ºä¾‹æ ¼å¼:")
        print("  subject_id,density,height,greenery,...,response")
        print("  1,3,2,5,...,7.2")
        print("  1,1,5,3,...,8.1")
        print("  ...")
        sys.exit(1)

    # åˆå§‹åŒ–åˆ†æå™¨
    try:
        analyzer = Phase1DataAnalyzer(
            data_csv_path=STEP2_CONFIG["data_csv_path"],
            subject_col=STEP2_CONFIG["subject_col"],
            response_col=STEP2_CONFIG["response_col"],
        )
    except Exception as e:
        print(f"[é”™è¯¯] åŠ è½½æ•°æ®å¤±è´¥: {e}")
        sys.exit(1)

    # æ‰§è¡Œåˆ†æ
    print("åˆ†æå‚æ•°:")
    print(f"  äº¤äº’å¯¹èŒƒå›´: {STEP2_CONFIG['min_pairs']}-{STEP2_CONFIG['max_pairs']}ä¸ª")
    print(f"  é€‰æ‹©æ–¹æ³•: {STEP2_CONFIG['selection_method']}")
    print()

    try:
        analysis = analyzer.analyze(
            max_pairs=STEP2_CONFIG["max_pairs"],
            min_pairs=STEP2_CONFIG["min_pairs"],
            selection_method=STEP2_CONFIG["selection_method"],
            verbose=True,
        )
    except Exception as e:
        print(f"[é”™è¯¯] åˆ†æå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # ç”ŸæˆPhase 2é…ç½®
    print()
    print("Phase 2é…ç½®å‚æ•°:")
    print(f"  è¢«è¯•æ•°: {STEP2_CONFIG['phase2_n_subjects']}äºº")
    print(f"  æ¯äººtrials: {STEP2_CONFIG['phase2_trials_per_subject']}æ¬¡")
    print(f"  Î»è°ƒæ•´ç³»æ•°: {STEP2_CONFIG['lambda_adjustment']}")
    print()

    try:
        phase2_config = analyzer.generate_phase2_config(
            n_subjects=STEP2_CONFIG["phase2_n_subjects"],
            trials_per_subject=STEP2_CONFIG["phase2_trials_per_subject"],
            lambda_adjustment=STEP2_CONFIG["lambda_adjustment"],
        )

        print("Phase 2é…ç½®:")
        print(f"  æ€»é¢„ç®—: {phase2_config['total_budget']}æ¬¡")
        print(f"  ç­›é€‰çš„äº¤äº’å¯¹: {len(phase2_config['interaction_pairs'])}ä¸ª")
        print(
            f"  Î»: {phase2_config['lambda_init']:.3f} -> {phase2_config['lambda_end']:.3f}"
        )
        print(
            f"  Î³: {phase2_config['gamma_init']:.3f} -> {phase2_config['gamma_end']:.3f}"
        )
        print(f"  ä¸­æœŸè¯Šæ–­: ç¬¬{phase2_config['mid_diagnostic_trial']}æ¬¡trial")
        print()

    except Exception as e:
        print(f"[é”™è¯¯] ç”ŸæˆPhase 2é…ç½®å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # å¯¼å‡ºæŠ¥å‘Š
    try:
        exported_files = analyzer.export_report(
            phase2_config=phase2_config,
            output_dir=STEP2_CONFIG["output_dir"],
            prefix=STEP2_CONFIG["prefix"],
            report_format=STEP2_CONFIG.get("report_format", "md"),
        )

        print("[OK] åˆ†æå®Œæˆï¼")
        print()
        print("=" * 80)
        print("ä¸‹ä¸€æ­¥ï¼š")
        print("  1. æŸ¥çœ‹åˆ†ææŠ¥å‘Š:")
        print(f"     {exported_files['report']}")
        print("  2. é˜…è¯»Phase 2ä½¿ç”¨æŒ‡å—:")
        print(f"     {exported_files['usage_guide']}")
        print("  3. åœ¨EUR-ANOVAä¸­åŠ è½½é…ç½®:")
        print(f"     - JSON: {exported_files['json_config']}")
        print(f"     - NumPy: {exported_files['npz_schedules']}")
        print("=" * 80)
        print()

    except Exception as e:
        print(f"[é”™è¯¯] å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


def run_step3():
    """è¿è¡Œæ­¥éª¤3ï¼šè®­ç»ƒ Base GP & æ‰«æè®¾è®¡ç©ºé—´"""
    print("=" * 80)
    print("æ­¥éª¤3ï¼šBase GP è®­ç»ƒä¸è®¾è®¡ç©ºé—´æ‰«æ")
    print("=" * 80)
    print()

    # ä½¿ç”¨æ–°çš„ APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if API_AVAILABLE:
        try:
            config = _dict_to_step3_config(STEP3_CONFIG)
            result = api_run_step3(config)

            print("[OK] Base GP è®­ç»ƒä¸æ‰«æå®Œæˆ")
            print(f"  è¾“å‡ºç›®å½•: {result.output_dir}")
            print(f"  è®¾è®¡ç©ºé—´ç‚¹æ•°: {result.n_design_points}")
            print("  å…³é”®ç‚¹: ä¿å­˜äº base_gp_key_points.json")
            print("  é•¿åº¦å°ºåº¦: base_gp_lengthscales.json")
            print("  æŠ¥å‘Š: base_gp_report.md")
            print()
            print("ä¸‹ä¸€æ­¥ï¼šå¯åœ¨ Phase 2 æ¨¡å‹ä¸­åŠ è½½ base_gp_state.pth ä½œä¸ºå½¢çŠ¶å‡½æ•°å…ˆéªŒ")
            return

        except Exception as e:
            print(f"[è­¦å‘Š] æ–° API è¿è¡Œå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿå®ç°: {e}")

    # ä¼ ç»Ÿå®ç°ï¼ˆå‘åå…¼å®¹ï¼‰
    from core.phase1_step3_base_gp import process_step3

    cfg = STEP3_CONFIG
    print("é…ç½®å‚æ•°:")
    print(f"  Phase1æ•°æ®: {cfg['data_csv_path']}")
    print(f"  è®¾è®¡ç©ºé—´:   {cfg['design_space_csv']}")
    print(f"  è¢«è¯•åˆ—:     {cfg['subject_col']}")
    print(f"  å“åº”åˆ—:     {cfg['response_col']}")
    print(f"  è¿­ä»£æ•°:     {cfg['max_iters']}")
    print(f"  å­¦ä¹ ç‡:     {cfg['learning_rate']}")
    print(f"  ä½¿ç”¨CUDA:   {cfg['use_cuda']}")
    print(f"  å¤šæ ·æ€§æ£€æŸ¥: {cfg.get('ensure_diversity', True)}")
    print(f"  è¾“å‡ºç›®å½•:   {cfg['output_dir']}")
    print()

    try:
        result = process_step3(
            data_csv_path=cfg["data_csv_path"],
            design_space_csv=cfg["design_space_csv"],
            subject_col=cfg["subject_col"],
            response_col=cfg["response_col"],
            output_dir=cfg["output_dir"],
            max_iters=cfg["max_iters"],
            lr=cfg["learning_rate"],
            use_cuda=cfg["use_cuda"],
            ensure_diversity=cfg.get("ensure_diversity", True),
        )
    except Exception as e:
        print(f"[é”™è¯¯] Step3 å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    print("[OK] Base GP è®­ç»ƒä¸æ‰«æå®Œæˆ")
    print(f"  è¾“å‡ºç›®å½•: {result['output_dir']}")
    print(f"  è®¾è®¡ç©ºé—´ç‚¹æ•°: {result['n_design_points']}")
    print("  å…³é”®ç‚¹: ä¿å­˜äº base_gp_key_points.json")
    print("  é•¿åº¦å°ºåº¦: base_gp_lengthscales.json")
    print("  æŠ¥å‘Š: base_gp_report.md")
    print()
    print("ä¸‹ä¸€æ­¥ï¼šå¯åœ¨ Phase 2 æ¨¡å‹ä¸­åŠ è½½ base_gp_state.pth ä½œä¸ºå½¢çŠ¶å‡½æ•°å…ˆéªŒ")


def run_step2_plus_3():
    """æ•´åˆè¿è¡Œ Step 2 å’Œ Step 3ï¼Œå¹¶ç”Ÿæˆç»Ÿä¸€æŠ¥å‘Š"""
    print("=" * 80)
    print("Phase 1 å®Œæ•´åˆ†æï¼šStep 2 (äº¤äº’å¯¹) + Step 3 (Base GP)")
    print("=" * 80)
    print()

    # ========== Step 2: äº¤äº’å¯¹åˆ†æ ==========
    print("=" * 80)
    print("ç¬¬ä¸€éƒ¨åˆ†ï¼šäº¤äº’å¯¹ç­›é€‰ä¸ Phase 2 å‚æ•°ä¼°è®¡")
    print("=" * 80)
    print()

    from core.analyze_phase1 import Phase1DataAnalyzer
    import json

    # è¿è¡Œ Step 2
    try:
        analyzer = Phase1DataAnalyzer(
            data_csv_path=STEP2_CONFIG["data_csv_path"],
            subject_col=STEP2_CONFIG["subject_col"],
            response_col=STEP2_CONFIG["response_col"],
        )

        analysis = analyzer.analyze(
            max_pairs=STEP2_CONFIG["max_pairs"],
            min_pairs=STEP2_CONFIG["min_pairs"],
            selection_method=STEP2_CONFIG["selection_method"],
            verbose=True,
        )

        phase2_config = analyzer.generate_phase2_config(
            n_subjects=STEP2_CONFIG["phase2_n_subjects"],
            trials_per_subject=STEP2_CONFIG["phase2_trials_per_subject"],
            lambda_adjustment=STEP2_CONFIG["lambda_adjustment"],
        )

        exported_files = analyzer.export_report(
            phase2_config=phase2_config,
            output_dir=STEP2_CONFIG["output_dir"],
            prefix=STEP2_CONFIG["prefix"],
            report_format=STEP2_CONFIG["report_format"],
        )

        print(f"\n[OK] Step 2 å®Œæˆï¼ç­›é€‰äº† {len(analysis['selected_pairs'])} ä¸ªäº¤äº’å¯¹")
        print(f"     æŠ¥å‘Šï¼š{exported_files['report']}")

    except Exception as e:
        print(f"[é”™è¯¯] Step 2 å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # ========== Step 3: Base GP è®­ç»ƒ ==========
    print()
    print("=" * 80)
    print("ç¬¬äºŒéƒ¨åˆ†ï¼šBase GP æ•æ„Ÿåº¦åˆ†æä¸å…³é”®ç‚¹é€‰æ‹©")
    print("=" * 80)
    print()

    from core.phase1_step3_base_gp import process_step3

    try:
        result_step3 = process_step3(
            data_csv_path=STEP3_CONFIG["data_csv_path"],
            design_space_csv=STEP3_CONFIG["design_space_csv"],
            subject_col=STEP3_CONFIG["subject_col"],
            response_col=STEP3_CONFIG["response_col"],
            output_dir=STEP3_CONFIG["output_dir"],
            max_iters=STEP3_CONFIG["max_iters"],
            lr=STEP3_CONFIG["learning_rate"],
            use_cuda=STEP3_CONFIG["use_cuda"],
            ensure_diversity=STEP3_CONFIG.get("ensure_diversity", True),
        )

        print(f"\n[OK] Step 3 å®Œæˆï¼è®­ç»ƒäº† Base GP æ¨¡å‹")
        print(f"     æŠ¥å‘Šï¼š{Path(result_step3['output_dir']) / 'base_gp_report.md'}")

    except Exception as e:
        print(f"[é”™è¯¯] Step 3 å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    # ========== ç”Ÿæˆæ•´åˆæŠ¥å‘Š ==========
    print()
    print("=" * 80)
    print("ç¬¬ä¸‰éƒ¨åˆ†ï¼šç”Ÿæˆæ•´åˆåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print()

    _generate_integrated_report(
        step2_dir=Path(exported_files["report"]).parent,
        step3_dir=Path(result_step3["output_dir"]),
        analysis=analysis,
        phase2_config=phase2_config,
        lengthscales=result_step3["lengthscales"],
        key_points=result_step3["key_points"],
    )


def _generate_integrated_report(
    step2_dir: Path,
    step3_dir: Path,
    analysis: dict,
    phase2_config: dict,
    lengthscales: list,
    key_points: dict,
):
    """ç”Ÿæˆ Step 2 + Step 3 çš„æ•´åˆåˆ†ææŠ¥å‘Š"""
    import json

    # åˆ›å»ºæ•´åˆæŠ¥å‘Šç›®å½•
    integrated_dir = step2_dir.parent / f"integrated_{step2_dir.name}"
    print(f"[Debug] Step2 dir: {step2_dir}")
    print(f"[Debug] Step2 dir parent: {step2_dir.parent}")
    print(f"[Debug] Integrated dir path: {integrated_dir}")
    integrated_dir.mkdir(exist_ok=True)
    print(f"[Debug] Directory exists: {integrated_dir.exists()}")

    # è¯»å–å› å­åç§°
    step3_lengthscales_file = step3_dir / "base_gp_lengthscales.json"
    with open(step3_lengthscales_file) as f:
        ls_data = json.load(f)
    factor_names = ls_data["factor_names"]

    # ç”Ÿæˆæ•´åˆæŠ¥å‘Š
    report_path = integrated_dir / "INTEGRATED_ANALYSIS_REPORT.md"

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# Phase 1 å®Œæ•´åˆ†ææŠ¥å‘Š\n\n")
        f.write(
            "> **æ•´åˆäº† Step 2 (äº¤äº’å¯¹åˆ†æ) å’Œ Step 3 (Base GP æ•æ„Ÿåº¦åˆ†æ) çš„ç»“æœ**\n\n"
        )
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")

        # ===== æ ¸å¿ƒå‘ç° =====
        f.write("## æ ¸å¿ƒå‘ç°\n\n")

        # äº¤äº’å¯¹
        f.write("### 1. å…³é”®äº¤äº’å¯¹ï¼ˆæ¥è‡ª Step 2ï¼‰\n\n")
        f.write(f"ç­›é€‰å‡º **{len(analysis['selected_pairs'])}** ä¸ªé‡è¦äº¤äº’å¯¹ï¼š\n\n")
        f.write("| æ’å | äº¤äº’å¯¹ | è¯„åˆ† | ç³»æ•° |\n")
        f.write("|------|--------|------|------|\n")

        # Get interaction scores and effects
        interaction_scores = analysis.get("diagnostics", {}).get(
            "interaction_scores", {}
        )
        interaction_effects = analysis.get("interaction_effects", {})

        for i, pair in enumerate(analysis["selected_pairs"], 1):
            idx1, idx2 = pair  # pair is a tuple like (2, 5)
            f1 = factor_names[idx1]
            f2 = factor_names[idx2]
            score = interaction_scores.get(pair, 0.0)

            # Get coefficient from interaction_effects if available
            effect_info = interaction_effects.get(pair, {})
            if isinstance(effect_info, dict):
                coef = effect_info.get("coef_interaction", 0.0)
            else:
                coef = 0.0

            f.write(f"| {i} | **{f1}** Ã— **{f2}** | {score:.3f} | {coef:.3f} |\n")

        f.write("\n")

        # å› å­æ•æ„Ÿåº¦
        f.write("### 2. å› å­æ•æ„Ÿåº¦æ’åºï¼ˆæ¥è‡ª Step 3 ARDï¼‰\n\n")
        f.write("åŸºäº Base GP çš„è‡ªåŠ¨ç›¸å…³æ€§åˆ¤æ–­ï¼ˆARDï¼‰ï¼š\n\n")
        f.write("| æ’å | å› å­ | é•¿åº¦å°ºåº¦ | æ•æ„Ÿåº¦ | å‚ä¸äº¤äº’æ•° |\n")
        f.write("|------|------|----------|--------|------------|\n")

        # ç»Ÿè®¡æ¯ä¸ªå› å­å‚ä¸çš„äº¤äº’æ•°
        interaction_count = {i: 0 for i in range(len(factor_names))}
        for pair in analysis["selected_pairs"]:
            idx1, idx2 = pair  # pair is a tuple like (2, 5)
            interaction_count[idx1] += 1
            interaction_count[idx2] += 1

        # æŒ‰é•¿åº¦å°ºåº¦æ’åºï¼ˆå°åˆ°å¤§ = é«˜æ•æ„Ÿåˆ°ä½æ•æ„Ÿï¼‰
        sorted_factors = sorted(enumerate(lengthscales), key=lambda x: x[1])

        for rank, (idx, ls) in enumerate(sorted_factors, 1):
            fname = factor_names[idx]
            if rank <= len(sorted_factors) // 3:
                sensitivity = "*** é«˜"
            elif rank <= 2 * len(sorted_factors) // 3:
                sensitivity = "** ä¸­"
            else:
                sensitivity = "* ä½"

            n_interactions = interaction_count[idx]
            f.write(
                f"| {rank} | {fname} | {ls:.2f} | {sensitivity} | {n_interactions} ä¸ª |\n"
            )

        f.write("\n")

        # ===== æ ¸å¿ƒæ´å¯Ÿ =====
        f.write("## æ ¸å¿ƒæ´å¯Ÿï¼šäº¤äº’æ¨¡å¼åˆ†æ\n\n")

        # æ‰¾å‡ºäº¤äº’æœ€å¤šçš„å› å­
        max_interactions = max(interaction_count.values())
        interaction_hubs = [
            factor_names[i]
            for i, count in interaction_count.items()
            if count == max_interactions
        ]

        if max_interactions > 0:
            f.write(f"### äº¤äº’æ ¸å¿ƒå› å­ï¼š{', '.join(interaction_hubs)}\n\n")
            f.write(
                f"è¿™äº›å› å­å‚ä¸äº† **{max_interactions}/{len(analysis['selected_pairs'])}** ä¸ªäº¤äº’å¯¹ï¼Œè¡¨æ˜å…¶æ•ˆæœ**é«˜åº¦ä¾èµ–æƒ…å¢ƒ**ã€‚\n\n"
            )

        # å¯¹æ¯”ä¸»æ•ˆåº”æ•æ„Ÿåº¦å’Œäº¤äº’å‚ä¸åº¦
        f.write("### å› å­ç‰¹æ€§å¯¹æ¯”\n\n")
        f.write("| å› å­ | ä¸»æ•ˆåº”æ•æ„Ÿåº¦ | äº¤äº’å‚ä¸åº¦ | ç‰¹æ€§ |\n")
        f.write("|------|--------------|------------|------|\n")

        for idx, fname in enumerate(factor_names):
            ls = lengthscales[idx]
            n_int = interaction_count[idx]

            # åˆ¤æ–­æ•æ„Ÿåº¦ç±»åˆ«
            ls_rank = sorted_factors.index((idx, ls)) + 1
            if ls_rank <= len(sorted_factors) // 3:
                sens = "é«˜"
            elif ls_rank <= 2 * len(sorted_factors) // 3:
                sens = "ä¸­"
            else:
                sens = "ä½"

            # åˆ¤æ–­ç‰¹æ€§
            if sens == "é«˜" and n_int == 0:
                char = "ç‹¬ç«‹ä¸»æ•ˆåº”"
            elif sens in ["ä½", "ä¸­"] and n_int >= 3:
                char = "**æƒ…å¢ƒä¾èµ–å‹**"
            elif sens == "é«˜" and n_int > 0:
                char = "ä¸»æ•ˆåº” + äº¤äº’"
            else:
                char = "è°ƒèŠ‚å› å­"

            f.write(f"| {fname} | {sens} (LS={ls:.2f}) | {n_int} ä¸ª | {char} |\n")

        f.write("\n")

        # ===== ä¸‰ä¸ªå…³é”®é‡‡æ ·ç‚¹ =====
        f.write("## æ¨èçš„åˆå§‹é‡‡æ ·ç‚¹ï¼ˆæ¥è‡ª Step 3ï¼‰\n\n")
        f.write("è¿™äº›ç‚¹å¯ä½œä¸º Phase 2 çš„ warmup åˆå§‹åŒ–ï¼š\n\n")

        # Sample 1: Best
        f.write("### Sample 1: Best Priorï¼ˆé¢„æµ‹æœ€ä½³ï¼‰\n\n")
        best_coords = key_points["x_best_prior"]
        f.write(
            f"- **é¢„æµ‹å¾—åˆ†**: {key_points['best_mean']:.3f} (std={key_points['best_std']:.3f})\n"
        )
        f.write("- **å‚æ•°é…ç½®**:\n")
        for fname in factor_names:
            f.write(f"  - {fname}: {best_coords[fname]}\n")
        f.write("\n")

        # Sample 2: Worst
        f.write("### Sample 2: Worst Priorï¼ˆé¢„æµ‹æœ€å·®ï¼‰\n\n")
        worst_coords = key_points["x_worst_prior"]
        f.write(
            f"- **é¢„æµ‹å¾—åˆ†**: {key_points['worst_mean']:.3f} (std={key_points['worst_std']:.3f})\n"
        )
        f.write("- **å‚æ•°é…ç½®**:\n")
        for fname in factor_names:
            f.write(f"  - {fname}: {worst_coords[fname]}\n")
        f.write("\n")

        # Sample 3: Max Uncertainty
        f.write("### Sample 3: Max Uncertaintyï¼ˆæœ€ä¸ç¡®å®šï¼‰\n\n")
        maxstd_coords = key_points["x_max_std"]
        if key_points["used_center_point"]:
            f.write("**æ³¨æ„**: æ‰€æœ‰ç‚¹æ–¹å·®è¿‡ä½ï¼Œä½¿ç”¨è®¾è®¡ç©ºé—´ä¸­å¿ƒç‚¹\n\n")
        f.write(
            f"- **ä¸ç¡®å®šæ€§**: std={key_points['max_std']:.3f} (mean={key_points.get('max_std_mean', 0):.3f})\n"
        )
        f.write("- **å‚æ•°é…ç½®**:\n")
        for fname in factor_names:
            f.write(f"  - {fname}: {maxstd_coords[fname]}\n")
        f.write("\n")

        # ===== Phase 2 å»ºè®® =====
        f.write("## Phase 2 å®éªŒå»ºè®®\n\n")

        f.write("### æ¨èç­–ç•¥\n\n")
        f.write("åŸºäºæ•´åˆåˆ†æï¼Œå»ºè®® Phase 2 é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š\n\n")
        f.write("1. **EUR-ANOVA é…ç½®**ï¼ˆæ¥è‡ª Step 2ï¼‰:\n")
        f.write(f"   - äº¤äº’å¯¹: {len(analysis['selected_pairs'])} ä¸ª\n")
        f.write(
            f"   - Î» (äº¤äº’æƒé‡): {phase2_config['lambda_init']:.2f} â†’ {phase2_config['lambda_end']:.2f}\n"
        )
        f.write(
            f"   - Î³ (è¦†ç›–æƒé‡): {phase2_config['gamma_init']:.2f} â†’ {phase2_config['gamma_end']:.2f}\n"
        )
        f.write(f"   - æ€»é¢„ç®—: {phase2_config['total_budget']} æ¬¡\n\n")

        f.write("2. **åˆå§‹ Warmup ç‚¹**ï¼ˆæ¥è‡ª Step 3ï¼‰:\n")
        f.write("   - ä½¿ç”¨ 3 ä¸ªå…³é”®ç‚¹ä½œä¸ºåˆå§‹é‡‡æ ·\n")
        f.write("   - è¦†ç›–è®¾è®¡ç©ºé—´çš„å…³é”®åŒºåŸŸï¼ˆæœ€ä½³/æœ€å·®/æœ€ä¸ç¡®å®šï¼‰\n\n")

        f.write("3. **æ¢ç´¢ä¼˜å…ˆçº§**:\n")
        high_sens_factors = [
            factor_names[idx] for idx, _ in sorted_factors[: len(sorted_factors) // 3]
        ]
        high_int_factors = [fname for fname in interaction_hubs]

        f.write(f"   - **ä¼˜å…ˆæ¢ç´¢ä¸»æ•ˆåº”**: {', '.join(high_sens_factors)}\n")
        if high_int_factors:
            f.write(
                f"   - **é‡ç‚¹æ¢ç´¢äº¤äº’**: æ¶‰åŠ {', '.join(high_int_factors)} çš„ç»„åˆ\n"
            )
        f.write("\n")

        # ===== è¾“å‡ºæ–‡ä»¶ =====
        f.write("## ğŸ“¦ è¾“å‡ºæ–‡ä»¶\n\n")
        f.write("### Step 2 è¾“å‡º\n")
        f.write(f"- JSONé…ç½®: `{step2_dir / 'phase1_phase2_config.json'}`\n")
        f.write(f"- NumPyè°ƒåº¦: `{step2_dir / 'phase1_phase2_schedules.npz'}`\n")
        f.write(f"- è¯¦ç»†æŠ¥å‘Š: `{step2_dir / 'phase1_analysis_report.md'}`\n\n")

        f.write("### Step 3 è¾“å‡º\n")
        f.write(f"- GPæ¨¡å‹: `{step3_dir / 'base_gp_state.pth'}`\n")
        f.write(f"- å…³é”®ç‚¹: `{step3_dir / 'base_gp_key_points.json'}`\n")
        f.write(f"- é•¿åº¦å°ºåº¦: `{step3_dir / 'base_gp_lengthscales.json'}`\n")
        f.write(f"- è®¾è®¡ç©ºé—´æ‰«æ: `{step3_dir / 'design_space_scan.csv'}`\n")
        f.write(f"- è¯¦ç»†æŠ¥å‘Š: `{step3_dir / 'base_gp_report.md'}`\n\n")

        f.write("### æ•´åˆæŠ¥å‘Š\n")
        f.write(f"- **æœ¬æŠ¥å‘Š**: `{report_path}`\n\n")

        f.write("---\n\n")
        f.write("*è‡ªåŠ¨ç”Ÿæˆäº Phase 1 å®Œæ•´åˆ†ææµç¨‹*\n")

    print(f"[OK] æ•´åˆæŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_path}")
    print()
    print("=" * 80)
    print("Phase 1 å®Œæ•´åˆ†æå®Œæˆï¼")
    print("=" * 80)
    print()
    print("æŸ¥çœ‹ç»“æœï¼š")
    print(f"  - æ•´åˆæŠ¥å‘Š: {report_path}")
    print(f"  - Step 2 è¯¦æƒ…: {step2_dir}")
    print(f"  - Step 3 è¯¦æƒ…: {step3_dir}")
    print()


def run_chain12():
    """ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2"""
    print("=" * 80)
    print("é“¾å¼æµç¨‹ï¼šæ­¥éª¤1 -> æ­¥éª¤2")
    print("=" * 80)
    print()

    if not API_AVAILABLE:
        print(
            "[é”™è¯¯] æµç¨‹ç®¡ç†å™¨éœ€è¦æ–°çš„ API æ”¯æŒï¼Œè¯·ç¡®ä¿ config_models.py å’Œ warmup_api.py å¯ç”¨"
        )
        sys.exit(1)

    try:
        # åˆ›å»ºæ­¥éª¤1é…ç½®
        step1_config = _dict_to_step1_config(STEP1_CONFIG)

        # åˆ›å»ºæ­¥éª¤2é…ç½®
        step2_config = _dict_to_step2_config(STEP2_CONFIG)

        # åˆ›å»ºå¹¶æ‰§è¡Œé“¾å¼æµç¨‹
        chain = Step1Step2Chain(step1_config, step2_config)
        result = chain.execute()

        print("[OK] é“¾å¼æµç¨‹å®Œæˆï¼")
        print(f"  æ­¥éª¤1è¾“å‡º: {result.step1_result.output_dir}/")
        print(f"  æ­¥éª¤2è¾“å‡º: {result.step2_result.output_dir}/")
        print(f"  ç­›é€‰çš„äº¤äº’å¯¹: {len(result.step2_result.selected_pairs)}ä¸ª")
        print()
        print("=" * 80)
        print("ä¸‹ä¸€æ­¥ï¼šå¯åœ¨ Phase 2 æ¨¡å‹ä¸­ä½¿ç”¨åˆ†æç»“æœ")
        print("=" * 80)
        print()

    except Exception as e:
        print(f"[é”™è¯¯] é“¾å¼æµç¨‹å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


def run_chain123():
    """ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2->3"""
    print("=" * 80)
    print("é“¾å¼æµç¨‹ï¼šæ­¥éª¤1 -> æ­¥éª¤2 -> æ­¥éª¤3")
    print("=" * 80)
    print()

    if not API_AVAILABLE:
        print(
            "[é”™è¯¯] æµç¨‹ç®¡ç†å™¨éœ€è¦æ–°çš„ API æ”¯æŒï¼Œè¯·ç¡®ä¿ config_models.py å’Œ warmup_api.py å¯ç”¨"
        )
        sys.exit(1)

    try:
        # åˆ›å»ºæ‰€æœ‰æ­¥éª¤çš„é…ç½®
        step1_config = _dict_to_step1_config(STEP1_CONFIG)
        step2_config = _dict_to_step2_config(STEP2_CONFIG)
        step3_config = _dict_to_step3_config(STEP3_CONFIG)

        # åˆ›å»ºå¹¶æ‰§è¡Œé“¾å¼æµç¨‹
        chain = Step1Step2Step3Chain(step1_config, step2_config, step3_config)
        result = chain.execute()

        print("[OK] å®Œæ•´é“¾å¼æµç¨‹å®Œæˆï¼")
        print(f"  æ­¥éª¤1è¾“å‡º: {result.step1_result.output_dir}/")
        print(f"  æ­¥éª¤2è¾“å‡º: {result.step2_result.output_dir}/")
        print(f"  æ­¥éª¤3è¾“å‡º: {result.step3_result.output_dir}/")
        print(f"  ç­›é€‰çš„äº¤äº’å¯¹: {len(result.step2_result.selected_pairs)}ä¸ª")
        print(f"  è®¾è®¡ç©ºé—´ç‚¹æ•°: {result.step3_result.n_design_points}")
        print()
        print("=" * 80)
        print("ä¸‹ä¸€æ­¥ï¼šå¯åœ¨ Phase 2 æ¨¡å‹ä¸­ä½¿ç”¨æ‰€æœ‰åˆ†æç»“æœ")
        print("=" * 80)
        print()

    except Exception as e:
        print(f"[é”™è¯¯] é“¾å¼æµç¨‹å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


def run_step1_5():
    """æ‰§è¡Œ Step 1.5: æ¨¡æ‹Ÿè¢«è¯•ä½œç­”"""
    print("=" * 80)
    print("Step 1.5: æ¨¡æ‹Ÿè¢«è¯•ä½œç­”")
    print("=" * 80)
    print()

    # æ·»åŠ toolsç›®å½•åˆ°è·¯å¾„ï¼Œä½¿ç”¨æ–°çš„warmup_adapter V3
    tools_path = Path(__file__).parent.parent.parent / "tools"
    sys.path.insert(0, str(tools_path))

    try:
        from subject_simulator_v2.adapters.warmup_adapter import (
            run as simulate_responses,
        )
        import json

        config = STEP1_5_CONFIG.copy()
        input_dir = Path(config.pop("input_dir"))

        # æå–æ¨¡å‹æ˜¾ç¤ºé€‰é¡¹
        print_model = config.pop("print_model", True)
        save_model_summary = config.pop("save_model_summary", True)
        model_summary_format = config.pop("model_summary_format", "txt")

        # æ·»åŠ design_space_csvå‚æ•°ï¼ˆV3æ–¹æ³•éœ€è¦ï¼‰
        # ä½¿ç”¨ä¸STEP1ç›¸åŒçš„è®¾è®¡ç©ºé—´CSV
        if "design_space_csv" not in config:
            config["design_space_csv"] = STEP1_CONFIG["design_csv_path"]

        print(f"è¾“å…¥ç›®å½•: {input_dir}")
        print(f"éšæœºç§å­: {config['seed']}")
        print(f"è¾“å‡ºç±»å‹: {config['output_type']}")
        if config["output_type"] == "likert":
            print(f"  Likertçº§åˆ«: {config['likert_levels']}")
            print(f"  æ˜ å°„æ¨¡å¼: {config['likert_mode']}")
        print(f"äº¤äº’æ–¹æ³•: V3 (interaction-as-featuresï¼Œé»˜è®¤)")
        print(f"è®¾è®¡ç©ºé—´CSV: {config.get('design_space_csv', 'N/A')}")
        print()

        # è¿è¡Œæ¨¡æ‹Ÿï¼ˆä½¿ç”¨V3æ–¹æ³•ï¼Œé»˜è®¤å¯ç”¨interaction_as_features=Trueï¼‰
        simulate_responses(input_dir=input_dir, **config)

        result_dir = input_dir / "result"

        # ========== æ‰“å°å’Œä¿å­˜æ¨¡å‹è§„æ ¼ ==========
        if print_model or save_model_summary:
            # è¯»å–ç¬¬ä¸€ä¸ªè¢«è¯•çš„æ¨¡å‹è§„æ ¼ä½œä¸ºä»£è¡¨
            model_md_files = sorted(list(result_dir.glob("subject_*_model.md")))
            fixed_weights_file = result_dir / "fixed_weights_auto.json"

            if model_md_files:
                print()
                print("=" * 80)
                print("æ¨¡å‹è§„æ ¼æ€»è§ˆ")
                print("=" * 80)
                print()

                # è¯»å–å›ºå®šæƒé‡
                if fixed_weights_file.exists():
                    with open(fixed_weights_file, "r", encoding="utf-8") as f:
                        fixed_weights_data = json.load(f)
                        global_weights = fixed_weights_data.get("global", [])
                else:
                    global_weights = None

                # æ„å»ºæ¨¡å‹æ‘˜è¦
                model_summary_lines = []
                model_summary_lines.append("=" * 80)
                model_summary_lines.append("Step 1.5 æ¨¡æ‹Ÿè¢«è¯•æ¨¡å‹è§„æ ¼")
                model_summary_lines.append("=" * 80)
                model_summary_lines.append("")
                model_summary_lines.append("## æ¨¡å‹é…ç½®")
                model_summary_lines.append(f"- éšæœºç§å­: {config['seed']}")
                model_summary_lines.append(
                    f"- ä½¿ç”¨æ½œå˜é‡æ¨¡å‹: {config.get('use_latent', 'false')}"
                )
                model_summary_lines.append(f"- è¾“å‡ºç±»å‹: {config['output_type']}")
                if config["output_type"] == "likert":
                    model_summary_lines.append(
                        f"- Likertçº§åˆ«: {config['likert_levels']}"
                    )
                    model_summary_lines.append(
                        f"- Likertæ˜ å°„: {config.get('likert_mode', 'tanh')}"
                    )
                model_summary_lines.append("")

                model_summary_lines.append("## æ•°æ®ç”Ÿæˆå‚æ•°")
                model_summary_lines.append(
                    f"- ç¾¤ä½“å‡å€¼: {config.get('population_mean', 0.0)}"
                )
                model_summary_lines.append(
                    f"- ç¾¤ä½“æ ‡å‡†å·®: {config.get('population_std', 0.4)}"
                )
                model_summary_lines.append(
                    f"- ä¸ªä½“å·®å¼‚æ¯”ä¾‹: {config.get('individual_std_percent', 1.0)}"
                )
                model_summary_lines.append(
                    f"- ç‰¹å¾é—´ç›¸å…³: {config.get('individual_corr', 0.0)}"
                )
                model_summary_lines.append("")

                model_summary_lines.append("## äº¤äº’æ•ˆåº”é…ç½®")
                interaction_pairs = config.get("interaction_pairs", [])
                if interaction_pairs:
                    model_summary_lines.append(
                        f"- æŒ‡å®šäº¤äº’å¯¹: {len(interaction_pairs)}ä¸ª"
                    )
                    for i, (idx1, idx2) in enumerate(interaction_pairs, 1):
                        model_summary_lines.append(f"  {i}. x{idx1} Ã— x{idx2}")
                else:
                    model_summary_lines.append("- æ— æŒ‡å®šäº¤äº’å¯¹")
                model_summary_lines.append(
                    f"- éšæœºäº¤äº’é¡¹æ•°: {config.get('num_interactions', 0)}"
                )
                model_summary_lines.append(
                    f"- äº¤äº’æƒé‡å°ºåº¦: {config.get('interaction_scale', 1.0)}"
                )
                model_summary_lines.append("")

                # å…¨å±€å›ºå®šæƒé‡
                if global_weights:
                    model_summary_lines.append("## ç¾¤ä½“å›ºå®šæ•ˆåº”ï¼ˆæ‰€æœ‰è¢«è¯•å…±äº«ï¼‰")
                    model_summary_lines.append("")
                    for obs_idx, weights in enumerate(global_weights, 1):
                        model_summary_lines.append(f"### è¾“å‡ºå˜é‡ {obs_idx}")
                        for feat_idx, w in enumerate(weights, 1):
                            model_summary_lines.append(f"  x{feat_idx-1}: {w:+.5f}")
                        model_summary_lines.append("")

                model_summary_lines.append("## è¢«è¯•ä¸ªä½“å·®å¼‚")
                model_summary_lines.append("æ¯ä¸ªè¢«è¯•åœ¨ç¾¤ä½“å›ºå®šæ•ˆåº”åŸºç¡€ä¸Šæ·»åŠ éšæœºåå·®ï¼Œ")
                model_summary_lines.append(
                    f"åå·®æ ‡å‡†å·® = {config.get('individual_std_percent', 1.0)} Ã— {config.get('population_std', 0.4)} = {config.get('individual_std_percent', 1.0) * config.get('population_std', 0.4):.4f}"
                )
                model_summary_lines.append("")
                model_summary_lines.append(
                    f"è¯¦è§å„è¢«è¯•æ¨¡å‹æ–‡ä»¶: {result_dir}/subject_*_model.md"
                )
                model_summary_lines.append("")
                model_summary_lines.append("=" * 80)

                # æ‰“å°åˆ°æ§åˆ¶å°
                if print_model:
                    for line in model_summary_lines:
                        print(line)
                    print()

                # ä¿å­˜åˆ°æ–‡ä»¶
                if save_model_summary:
                    if model_summary_format in ["txt", "both"]:
                        summary_txt = result_dir / "MODEL_SUMMARY.txt"
                        with open(summary_txt, "w", encoding="utf-8") as f:
                            f.write("\n".join(model_summary_lines))
                        print(f"[ä¿å­˜] æ¨¡å‹æ‘˜è¦å·²ä¿å­˜è‡³: {summary_txt}")

                    if model_summary_format in ["md", "both"]:
                        summary_md = result_dir / "MODEL_SUMMARY.md"
                        # Markdownæ ¼å¼ç¨ä½œè°ƒæ•´
                        md_lines = [
                            line.replace("## ", "### ").replace("# ", "## ")
                            for line in model_summary_lines
                        ]
                        md_lines[0] = "# " + md_lines[0].strip("=").strip()  # æ ‡é¢˜
                        with open(summary_md, "w", encoding="utf-8") as f:
                            f.write("\n".join(md_lines))
                        print(f"[ä¿å­˜] æ¨¡å‹æ‘˜è¦å·²ä¿å­˜è‡³: {summary_md}")
                    print()

        print()
        print("=" * 80)
        print("[OK] æ¨¡æ‹Ÿåº”ç­”å®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {input_dir}/result/")
        if save_model_summary:
            print(f"æ¨¡å‹æ‘˜è¦: {result_dir}/MODEL_SUMMARY.{model_summary_format}")
        print("=" * 80)
        print()

    except ImportError as e:
        print(f"[é”™è¯¯] æ— æ³•å¯¼å…¥æ¨¡æ‹Ÿåº”ç­”æ¨¡å—: {e}")
        print("è¯·ç¡®ä¿ core/simulation_runner.py å’Œ core/single_output_subject.py å­˜åœ¨")
        sys.exit(1)
    except Exception as e:
        print(f"[é”™è¯¯] æ¨¡æ‹Ÿåº”ç­”å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 80)
    print("ä¸¤é˜¶æ®µå®éªŒè§„åˆ’ - å¿«é€Ÿå¯åŠ¨")
    print("=" * 80)
    print()

    if MODE == "step1":
        run_step1()
    elif MODE == "step1.5":
        run_step1_5()
    elif MODE == "step2":
        run_step2()
    elif MODE == "step3":
        run_step3()
    elif MODE == "step2+3":
        print("[æ¨¡å¼] æ•´åˆåˆ†æï¼šStep 2 + Step 3")
        run_step2_plus_3()
    elif MODE == "both":
        print("[æ¨¡å¼] è¿ç»­è¿è¡Œä¸¤æ­¥")
        print()
        run_step1()
        print()
        print("=" * 80)
        print("è¯·å…ˆæ‰§è¡Œå®éªŒï¼Œæ”¶é›†å“åº”æ•°æ®åï¼Œå†ç»§ç»­è¿è¡Œæ­¥éª¤2")
        print("=" * 80)
        print()
        input("æŒ‰Enterç»§ç»­è¿è¡Œæ­¥éª¤2...")
        print()
        run_step2()
    elif MODE == "all":
        print("[æ¨¡å¼] è¿è¡Œ Step1 -> Step1.5(æ¨¡æ‹Ÿ) -> Step2 -> Step3 (all æ¨¡å¼)")

        # å‡†å¤‡ç»Ÿä¸€è¾“å‡ºç›®å½•ç»“æ„
        ts = time.strftime("%Y%m%d%H%M")
        base_out = Path(ALL_CONFIG.get("base_output_dir")) / ts
        step1_out = base_out / "step1"
        step1_5_out = base_out / "step1_5"
        step2_out = base_out / "step2"
        step3_out = base_out / "step3"

        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        base_out.mkdir(parents=True, exist_ok=True)

        # è¦†ç›–å„æ­¥éª¤çš„è¾“å‡º/è¾“å…¥è·¯å¾„
        # å¦‚æœ ALL_CONFIG æŒ‡å®šäº†è®¾è®¡ç©ºé—´æ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆè¦†ç›– STEP1_CONFIGï¼‰
        if ALL_CONFIG.get("design_csv"):
            STEP1_CONFIG["design_csv_path"] = ALL_CONFIG.get("design_csv")

        STEP1_CONFIG["output_dir"] = str(step1_out)

        # Step1.5 çš„ input_dir æŒ‡å‘ Step1 è¾“å‡ºï¼ˆå¦‚æœé…ç½®å…è®¸è‡ªåŠ¨è¿è¡Œæ¨¡æ‹Ÿï¼‰
        if ALL_CONFIG.get("run_step1_5", True):
            STEP1_5_CONFIG["input_dir"] = str(step1_out)
        # Step1.5 çš„è¾“å‡ºä¼šå†™å…¥ input_dir/result/
        # å¦‚æœ ALL_CONFIG æŒ‡å®šäº† step2_data_csvï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨
        if ALL_CONFIG.get("step2_data_csv"):
            STEP2_CONFIG["data_csv_path"] = ALL_CONFIG.get("step2_data_csv")
        else:
            # Step2 ä½¿ç”¨ Step1.5 çš„ result ç›®å½•ä½œä¸º data sourceï¼ˆä¼˜å…ˆï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ Step1 çš„ result
            if ALL_CONFIG.get("run_step1_5", True) and ALL_CONFIG.get(
                "step1_5_use_result_dir_for_step2", True
            ):
                STEP2_CONFIG["data_csv_path"] = str(step1_5_out / "result")
            else:
                STEP2_CONFIG["data_csv_path"] = str(step1_out / "result")

        # è¦†ç›– Step2/Step3 çš„è¾“å‡ºç›®å½•
        STEP2_CONFIG["output_dir"] = str(step2_out)
        STEP3_CONFIG["output_dir"] = str(step3_out)

        # Step3 ä½¿ç”¨ Step2 çš„æ•°æ®è¾“å‡ºä½œä¸ºè¾“å…¥
        # å¦‚æœ ALL_CONFIG æŒ‡å®šäº† step3 çš„ design_spaceï¼Œåˆ™è¦†ç›– Step3 çš„ design_space_csv
        if ALL_CONFIG.get("step3_design_space_csv"):
            STEP3_CONFIG["design_space_csv"] = ALL_CONFIG.get("step3_design_space_csv")

        STEP3_CONFIG["data_csv_path"] = STEP2_CONFIG["data_csv_path"]

        # è¿è¡Œæ­¥éª¤
        run_step1()
        print()
        print("=" * 80)
        if ALL_CONFIG.get("run_step1_5", True):
            print("è‡ªåŠ¨è¿è¡Œæ¨¡æ‹Ÿåº”ç­” (Step1.5)...")
            print("=" * 80)

            # å°† Step1 çš„è¾“å‡ºå¤åˆ¶åˆ°å•ç‹¬çš„ step1_5 è¾“å…¥ç›®å½•ï¼Œä¿è¯æ¯ä¸ªæ­¥éª¤æœ‰ç‹¬ç«‹ç›®å½•
            try:
                import shutil

                if Path(STEP1_CONFIG["output_dir"]).exists():
                    step1_5_out.mkdir(parents=True, exist_ok=True)
                    for item in Path(STEP1_CONFIG["output_dir"]).iterdir():
                        dest = step1_5_out / item.name
                        if item.is_dir():
                            if dest.exists():
                                shutil.rmtree(dest)
                            shutil.copytree(item, dest)
                        else:
                            shutil.copy2(item, dest)
                # å°†æ¨¡æ‹Ÿè¾“å…¥æŒ‡å‘å¤åˆ¶åçš„ç›®å½•
                STEP1_5_CONFIG["input_dir"] = str(step1_5_out)
            except Exception as e:
                print(f"[è­¦å‘Š] å¤åˆ¶ Step1 è¾“å‡ºåˆ° step1_5 ç›®å½•å¤±è´¥: {e}")
                print("ç»§ç»­ä½¿ç”¨ Step1 è¾“å‡ºç›®å½•ä½œä¸ºæ¨¡æ‹Ÿè¾“å…¥")
                STEP1_5_CONFIG["input_dir"] = str(step1_out)

            run_step1_5()
            print()
        print("=" * 80)
        print("ç»§ç»­è¿è¡Œ Step2 åˆ†ææ•°æ®...")
        print("=" * 80)
        print()
        run_step2()
        print()
        print("=" * 80)
        print("ç»§ç»­è¿è¡Œ Step3 (Base GP)...")
        print("=" * 80)
        print()
        run_step3()
    elif MODE == "chain12":
        print("[æ¨¡å¼] ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2")
        run_chain12()
    elif MODE == "chain123":
        print("[æ¨¡å¼] ä½¿ç”¨æµç¨‹ç®¡ç†å™¨è¿è¡Œæ­¥éª¤1->2->3")
        run_chain123()
    else:
        print(f"[é”™è¯¯] æœªçŸ¥çš„æ¨¡å¼: {MODE}")
        print(
            "è¯·è®¾ç½® MODE ä¸º 'step1', 'step1.5', 'step2', 'step3', 'step2+3', 'both', 'all', 'chain12', æˆ– 'chain123'"
        )
        sys.exit(1)


if __name__ == "__main__":
    main()
