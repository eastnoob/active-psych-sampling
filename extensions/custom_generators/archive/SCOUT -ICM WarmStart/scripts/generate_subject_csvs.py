#!/usr/bin/env python3
"""
Generate per-subject trial CSV files from combined trial schedule.

This script reads the combined trial_schedule.csv generated by run_warmup_sampling.py
and creates individual CSV files for each subject (subject_0.csv, subject_1.csv, etc.).

Usage:
    python generate_subject_csvs.py --trial_schedule_csv <path> [--output_dir <path>]
"""

import argparse
import sys
from pathlib import Path
import pandas as pd
import logging


def setup_logging(output_dir: Path) -> logging.Logger:
    """Set up logging to file and console."""
    logger = logging.getLogger("subject_csvs")
    logger.setLevel(logging.INFO)

    # File handler
    log_file = output_dir / "generate_subject_csvs.log"
    fh = logging.FileHandler(log_file)
    fh.setLevel(logging.INFO)

    # Console handler
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)

    # Formatter
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)

    logger.addHandler(fh)
    logger.addHandler(ch)

    return logger


def generate_subject_csvs(
    trial_schedule_csv: str,
    output_dir: str = None,
    logger: logging.Logger = None,
    n_subjects: int = None,
) -> dict:
    """
    Generate per-subject CSV files from combined trial schedule.

    Args:
        trial_schedule_csv: Path to combined trial_schedule.csv
        output_dir: Output directory (defaults to same dir as trial_schedule_csv)
        logger: Logger instance
        n_subjects: Number of subjects to keep (filters out extra subjects created by generator)
                   If None, uses all unique subject_ids in the CSV

    Returns:
        Dictionary with summary of generated files
    """
    if logger is None:
        logger = logging.getLogger("subject_csvs")

    # Validate input
    trial_csv_path = Path(trial_schedule_csv)
    if not trial_csv_path.exists():
        raise FileNotFoundError(f"Trial schedule not found: {trial_schedule_csv}")

    # Set output directory
    if output_dir is None:
        output_dir = trial_csv_path.parent
    else:
        output_dir = Path(output_dir)

    # Read combined trial schedule
    logger.info(f"Reading trial schedule: {trial_csv_path}")
    trials_df = pd.read_csv(trial_csv_path)
    logger.info(f"Loaded {len(trials_df)} total trials from combined schedule")

    # Get unique subject_ids and filter if needed
    all_subject_ids = sorted(trials_df["subject_id"].unique())
    logger.info(
        f"Found {len(all_subject_ids)} total subjects in data: {all_subject_ids}"
    )

    # If n_subjects specified, keep only the first n_subjects
    if n_subjects is not None and n_subjects > 0:
        subject_ids = all_subject_ids[:n_subjects]
        if len(subject_ids) < len(all_subject_ids):
            logger.info(
                f"Filtering to {n_subjects} subjects (specified parameter): {subject_ids}"
            )
            trials_df = trials_df[trials_df["subject_id"].isin(subject_ids)]
    else:
        subject_ids = all_subject_ids
        logger.info(f"Using all {len(subject_ids)} subjects found in data")

    # Generate per-subject CSV files
    generated_files = {}
    for subject_id in subject_ids:
        subject_trials = trials_df[trials_df["subject_id"] == subject_id].copy()

        # Sort by batch_id and block_type (for consistency)
        # Sort order: core1 -> core2 -> boundary -> lhs -> individual
        block_type_order = {
            "core1": 0,
            "core2": 1,
            "boundary": 2,
            "lhs": 3,
            "individual": 4,
        }
        subject_trials["_block_order"] = subject_trials["block_type"].map(
            block_type_order
        )
        subject_trials = subject_trials.sort_values(["batch_id", "_block_order"]).drop(
            columns=["_block_order"]
        )

        # Reset index for subject-local numbering
        subject_trials = subject_trials.reset_index(drop=True)
        subject_trials.insert(0, "trial_number", range(1, len(subject_trials) + 1))

        # Save to CSV
        output_file = output_dir / f"subject_{subject_id}.csv"
        subject_trials.to_csv(output_file, index=False)
        generated_files[subject_id] = str(output_file)

        logger.info(
            f"[OK] Subject {subject_id}: {len(subject_trials)} trials -> {output_file}"
        )

    # Summary
    logger.info("=" * 70)
    logger.info(f"Generated {len(generated_files)} per-subject CSV files")
    logger.info("=" * 70)

    return generated_files


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate per-subject trial CSV files from combined trial schedule"
    )
    parser.add_argument(
        "--trial_schedule_csv",
        required=True,
        help="Path to combined trial_schedule.csv (required)",
    )
    parser.add_argument(
        "--output_dir",
        default=None,
        help="Output directory for per-subject CSVs (defaults to same dir as trial_schedule_csv)",
    )
    parser.add_argument(
        "--n_subjects",
        type=int,
        default=None,
        help="Number of subjects to keep (filters out extra subjects). If None, uses all subjects in data.",
    )

    args = parser.parse_args()

    # Validate input
    trial_csv_path = Path(args.trial_schedule_csv)
    if not trial_csv_path.exists():
        print(f"[ERROR] Trial schedule not found: {args.trial_schedule_csv}")
        sys.exit(1)

    # Use trial_schedule.csv directory as default output
    if args.output_dir is None:
        output_dir = trial_csv_path.parent
    else:
        output_dir = Path(args.output_dir)

    # Set up logging
    logger = setup_logging(output_dir)
    logger.info("=" * 70)
    logger.info("Per-Subject CSV Generation Started")
    logger.info("=" * 70)

    try:
        # Generate subject CSVs
        files = generate_subject_csvs(
            trial_schedule_csv=str(trial_csv_path),
            output_dir=str(output_dir),
            logger=logger,
            n_subjects=args.n_subjects,
        )

        # Success
        logger.info("=" * 70)
        logger.info("[OK] Per-subject CSV generation completed successfully")
        logger.info("=" * 70)
        print("[OK] Per-subject CSV files generated successfully!")

    except Exception as e:
        logger.error(f"[ERROR] Error during generation: {e}", exc_info=True)
        print(f"[ERROR] Generation failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
